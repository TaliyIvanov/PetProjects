{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a316eb93-908a-4a51-a7ef-519ae5048b0d",
   "metadata": {},
   "source": [
    "### Before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab5fc6c-d073-4288-ab91-7a3943814894",
   "metadata": {},
   "source": [
    "#### Об этом ноутбуке\n",
    "Данный ноутбук является финальной частью.\n",
    "Он аккумулирует в себе предыдущие два + исследует решения коллег по цеху, для улучшения навыков в будущем.\n",
    "\n",
    "#### Цели данного ноутбука:\n",
    "- Провести \"работу над ошибками\" после участия [соревновании](https://www.kaggle.com/competitions/adengi-internship);\n",
    "- Подробно разобрать различные методы, которые используют коллеги для анализа ио бработки данных (методы заимствованы из этих ноутбуков: [Ноутбук1](https://www.kaggle.com/code/korcy78/baseline), [Ноутбук2](https://www.kaggle.com/code/alexaali/catboost-0-91-score))\n",
    "\n",
    "#### Description\n",
    "В этом соревновании вам нужно будет натренировать модель оттока, которая лучше всех сможет генерализовать общую зависимость оттока.\n",
    "\n",
    "#### Evaluation\n",
    "Ответы модели будут оценены с помощью F1 метрики между предсказанными ответами и реальными.\n",
    "\n",
    "#### Первые мысли\n",
    "По сути стандартная задача бинарной классификаци.\n",
    "\n",
    "Необходимо предсказать отток клиентов.\n",
    "\n",
    "В зависимости от кол-ва данных, будем выбирать модель.\n",
    "\n",
    "Предварительно, как многим известно, в подобных задачах себя очень хорошо зарекомендовали бустинги.\n",
    "Я взглянул на файлик train.csv, он весит 2.2Гб, данных много, я думаю лучшим решением будут именно бустинги.\n",
    "\n",
    "Но, т.к. я практикуюсь, мне не важно какой скор я выбью, лично мне важно попробовать разные подходы и поэкспериментировать.\n",
    "\n",
    "Разумеется в рамках разумных сроков(решаю эту задачу только по выходным).\n",
    "\n",
    "#### О данных\n",
    "- monthly_income - среднемесячный заработок клиента (зарплата)\n",
    "- payment_frequency - частота получения зарплаты (month - 1 раз в месяц, 2 weeks - раз в две недели, и тд)\n",
    "- status - статус клиента (самозанятый, рабочий, и тд)\n",
    "- work_experience - кол-во лет стажа клиента\n",
    "- client_type - тип клиента (новый, повторный)\n",
    "- settlement - город клиента\n",
    "- requested_sum - запрашиваемая сумма клиента для займа, если interface - alfa\n",
    "- region - регион клиента (область, округ, и тд)\n",
    "- loan_id - уникальный идентификатор займа\n",
    "- client_id - уникальный идентификатор клиента\n",
    "- main_agreement_amount - основная одобренная сумма клиенту по займу (может быть больше, чем approved_amount)\n",
    "- main_agreement_term - основной одобренный срок по займу\n",
    "- requested_period_days - запрашиваемый срок по займу\n",
    "- requested_amount - запрашиваемая сумма клиента по займу\n",
    "- req_app_amount - разница между запрашиваемой суммой займа и одобренной\n",
    "- approved_amount - одобренная сумма по займу\n",
    "- source - канал привлечения клиента\n",
    "- first_source - первый канал привлечения клиента\n",
    "- period_days - период страховки по займу\n",
    "- interface - интерфейс, откуда пришла заявка - (site, mobile)\n",
    "- created_at - дата открытия займа\n",
    "- type - тип займа (тип продукта)\n",
    "- closed_at - дата закрытия займа\n",
    "- days_finish_loan - время в днях, затраченное на закрытие займа (closed_at - created_at)\n",
    "- gender - пол клиента\n",
    "- ag - возраст клиента\n",
    "- repayment_type - Тип комиссии по займу (с 2.5% - with_comission, 5% - with_big_comission, 0% - no_comission)\n",
    "- loan_order - порядковый номер займа\n",
    "- have_extension - имеется ли пролонгация по данному займу\n",
    "- cnt_ext - кол-во пролонгаций по займу\n",
    "- start_dt - дата начала (список) пролонгаций по займу\n",
    "- term - срок пролонгации (список)\n",
    "- price - цена пролонгации (список)\n",
    "- elecs_sum - штрафы, пени\n",
    "- recurents_sum - штрафы, пени (там вроде как различия в этапах их начисления)\n",
    "- tamount - общий кэшфлоу клиента (общая сумма которая была на аккаунте клиента)\n",
    "- issues - сумма просрочек, штрафов и пени\n",
    "- principal - сумма основного долга\n",
    "- interest - прибыль с клиента\n",
    "- overdue_interest - прибыль с клиента, если есть прослойка\n",
    "- overdue_fee - штрафы в просрочек\n",
    "- contact_cases - кол-во обращений клиента с коллекшн\n",
    "- nbki_score - скор клиента от рисков\n",
    "\n",
    "- churn - колонка таргета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e2ea2-31ac-4b2b-81c5-0d61bdc7b83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95616c-a593-4ae3-a536-c04865816b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a68e0019-a732-402c-96f1-18537dce69fe",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c5fe1602-a50d-4aa6-a748-7fe1d2838700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "\n",
    "\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# Utilities\n",
    "from rapidfuzz import process, fuzz\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eaa456-a736-4ee0-9655-009253ee0b8a",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "977dd80c-2220-44e3-999b-b0023c7c5f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time is: 21.179394960403442 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "elapsed = time.time() - start\n",
    "print(f'Time is: {elapsed} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b2d1063d-df45-4437-9181-5862aefccaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time is: 6.376559019088745 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "elapsed = time.time() - start\n",
    "print(f'Time is: {elapsed} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb0857-208e-46d3-a317-3e1609a520bc",
   "metadata": {},
   "source": [
    "#### Оптимизация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "19534ffb-c504-4add-b92b-1feca27d3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_data(df):\n",
    "    # оптимизируем числовые данные\n",
    "    for col in df.select_dtypes(include=['int64']).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "    for col in df.select_dtypes(include=['float64']).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "\n",
    "    # Оптимизируем даты\n",
    "    df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
    "    df[\"start_dt\"] = pd.to_datetime(df[\"start_dt\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c95b51be-e18c-487d-9c94-18ff1066c263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета до оптимизации: 3231.96 MB\n",
      "Размер датасета после оптимизации: 2150.51 MB\n"
     ]
    }
   ],
   "source": [
    "# Размер трейна до оптимизации\n",
    "print(f\"Размер датасета до оптимизации: {train.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")\n",
    "train = optimize_data(train)\n",
    "# Размер трейна после оптимизации\n",
    "print(f\"Размер датасета после оптимизации: {train.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "56a2f996-0789-4ea4-a9e4-180330237235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета до оптимизации: 971.89 MB\n",
      "Размер датасета после оптимизации: 619.54 MB\n"
     ]
    }
   ],
   "source": [
    "# Размер теста до оптимизации\n",
    "print(f\"Размер датасета до оптимизации: {test.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")\n",
    "test = optimize_data(test)\n",
    "# Размер теста после оптимизации\n",
    "print(f\"Размер датасета после оптимизации: {test.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea0aa55-46aa-430a-b6b3-762343434fc5",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "- База:\n",
    "    - общая оценка данных\n",
    "    - проверка на дубликаты;\n",
    "    - обработка пропусков;\n",
    "    - грамотная обработка категориальных переменных;\n",
    "    - кодирование категориальных переменных;\n",
    "    - знакомство с балансом целевой переменной;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f88604c-a902-4bed-9cca-91b4fd0c71bc",
   "metadata": {},
   "source": [
    "### Общая оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e9acfd1f-73af-476b-8596-0d88f40d9cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4036207, 45)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a19e2f2e-c821-4da9-97e0-744708dc25b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1348743, 43)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55006a7-2df8-4dec-aaed-f88d049704a9",
   "metadata": {},
   "source": [
    "Количество фичей в трейне и тесте различно больше чем на единицу, следовательно из теста удалили некий признак, который остался в трейне.\n",
    "\n",
    "Оставлять его не имеет никакого смысла абсолютно)\n",
    "\n",
    "Ознакомимся с данными детальнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "30bcc356-6000-49e6-bb73-0c69dadfed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4036207 entries, 0 to 4036206\n",
      "Data columns (total 45 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   monthly_income         float32       \n",
      " 1   work_experience        float32       \n",
      " 2   requested_sum          float32       \n",
      " 3   main_agreement_amount  float32       \n",
      " 4   main_agreement_term    float32       \n",
      " 5   requested_period_days  float32       \n",
      " 6   requested_amount       float32       \n",
      " 7   req_app_amount         float32       \n",
      " 8   approved_amount        float32       \n",
      " 9   period_days            float32       \n",
      " 10  days_finish_loan       float32       \n",
      " 11  ag                     float32       \n",
      " 12  cnt_ext                float32       \n",
      " 13  term                   float32       \n",
      " 14  price                  float32       \n",
      " 15  elecs_sum              float32       \n",
      " 16  recurents_sum          float32       \n",
      " 17  tamount                float32       \n",
      " 18  issues                 float32       \n",
      " 19  principal              float32       \n",
      " 20  interest               float32       \n",
      " 21  overdue_interest       float32       \n",
      " 22  overdue_fee            float32       \n",
      " 23  nbki_score             float32       \n",
      " 24  payment_frequency      int8          \n",
      " 25  status                 int8          \n",
      " 26  loan_id                int32         \n",
      " 27  client_id              int32         \n",
      " 28  source                 int8          \n",
      " 29  first_source           int8          \n",
      " 30  interface              int8          \n",
      " 31  type                   int8          \n",
      " 32  repayment_type         int8          \n",
      " 33  client_type            int8          \n",
      " 34  settlement             object        \n",
      " 35  client_type.1          object        \n",
      " 36  region                 object        \n",
      " 37  gender                 object        \n",
      " 38  loan_order             int16         \n",
      " 39  have_extension         int8          \n",
      " 40  contact_cases          float32       \n",
      " 41  created_at             datetime64[ns]\n",
      " 42  closed_at              object        \n",
      " 43  start_dt               datetime64[ns]\n",
      " 44  churn                  int8          \n",
      "dtypes: datetime64[ns](2), float32(25), int16(1), int32(2), int8(10), object(5)\n",
      "memory usage: 677.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6484d92-20b3-479b-9466-ab1f93e121d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1348743 entries, 0 to 1348742\n",
      "Data columns (total 43 columns):\n",
      " #   Column                 Non-Null Count    Dtype         \n",
      "---  ------                 --------------    -----         \n",
      " 0   monthly_income         1348680 non-null  float32       \n",
      " 1   work_experience        463225 non-null   float32       \n",
      " 2   requested_sum          163790 non-null   float32       \n",
      " 3   main_agreement_amount  1348743 non-null  float32       \n",
      " 4   main_agreement_term    1348743 non-null  float32       \n",
      " 5   requested_period_days  1200882 non-null  float32       \n",
      " 6   requested_amount       1209772 non-null  float32       \n",
      " 7   req_app_amount         1209772 non-null  float32       \n",
      " 8   approved_amount        1348743 non-null  float32       \n",
      " 9   period_days            1348743 non-null  float32       \n",
      " 10  days_finish_loan       1348743 non-null  float32       \n",
      " 11  ag                     1348743 non-null  float32       \n",
      " 12  cnt_ext                151701 non-null   float32       \n",
      " 13  term                   151701 non-null   float32       \n",
      " 14  price                  151610 non-null   float32       \n",
      " 15  elecs_sum              1346759 non-null  float32       \n",
      " 16  recurents_sum          1346759 non-null  float32       \n",
      " 17  tamount                1348125 non-null  float32       \n",
      " 18  issues                 1348743 non-null  float32       \n",
      " 19  principal              1348743 non-null  float32       \n",
      " 20  interest               1348743 non-null  float32       \n",
      " 21  overdue_interest       1348743 non-null  float32       \n",
      " 22  overdue_fee            1348743 non-null  float32       \n",
      " 23  nbki_score             1320766 non-null  float32       \n",
      " 24  payment_frequency      1348743 non-null  int8          \n",
      " 25  status                 1348743 non-null  int8          \n",
      " 26  loan_id                1348743 non-null  int32         \n",
      " 27  client_id              1348743 non-null  int32         \n",
      " 28  source                 1348743 non-null  int8          \n",
      " 29  first_source           1348743 non-null  int8          \n",
      " 30  interface              1348743 non-null  int8          \n",
      " 31  type                   1348743 non-null  int8          \n",
      " 32  repayment_type         1348743 non-null  int8          \n",
      " 33  client_type            1348743 non-null  int8          \n",
      " 34  settlement             1348743 non-null  object        \n",
      " 35  client_type.1          1348743 non-null  object        \n",
      " 36  region                 1348743 non-null  object        \n",
      " 37  gender                 1348743 non-null  object        \n",
      " 38  loan_order             1348743 non-null  int16         \n",
      " 39  have_extension         1348743 non-null  int8          \n",
      " 40  contact_cases          75952 non-null    float32       \n",
      " 41  created_at             1348743 non-null  datetime64[ns]\n",
      " 42  start_dt               151075 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float32(25), int16(1), int32(2), int8(9), object(4)\n",
      "memory usage: 214.8+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dfc98f1a-65e3-4b42-9f2a-37dd8b164ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#лишним является 'closed_at', без зазрений совести дропаем его из трейна\n",
    "train.drop('closed_at', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "69eada53-2a9d-4ace-97e9-b6c614a984a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          False\n",
       "1          False\n",
       "2          False\n",
       "3          False\n",
       "4          False\n",
       "           ...  \n",
       "1348738    False\n",
       "1348739    False\n",
       "1348740    False\n",
       "1348741    False\n",
       "1348742    False\n",
       "Length: 1348743, dtype: bool"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# так же есть задвоенный категориальный признак\n",
    "test['client_type'] == test['client_type.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "acd5dfae-d9d2-4d65-84fb-11f70af4f90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "Name: client_type, dtype: int8\n",
      "0    repeated\n",
      "1    repeated\n",
      "2         new\n",
      "3    repeated\n",
      "4    repeated\n",
      "Name: client_type.1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test['client_type'][:5], test['client_type.1'][:5], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b05a720e-7c2d-4d46-ba8c-9034eb1f1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# избавимся и от него\n",
    "train.drop('client_type.1', axis=1, inplace=True)\n",
    "test.drop('client_type.1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dff7dae1-dc20-4b84-9741-241f440cd8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[1] == test.shape[1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eb5b3a15-25f5-43b7-946b-ea8163487977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>work_experience</th>\n",
       "      <th>requested_sum</th>\n",
       "      <th>main_agreement_amount</th>\n",
       "      <th>main_agreement_term</th>\n",
       "      <th>requested_period_days</th>\n",
       "      <th>requested_amount</th>\n",
       "      <th>req_app_amount</th>\n",
       "      <th>approved_amount</th>\n",
       "      <th>period_days</th>\n",
       "      <th>...</th>\n",
       "      <th>interface</th>\n",
       "      <th>type</th>\n",
       "      <th>repayment_type</th>\n",
       "      <th>client_type</th>\n",
       "      <th>loan_order</th>\n",
       "      <th>have_extension</th>\n",
       "      <th>contact_cases</th>\n",
       "      <th>created_at</th>\n",
       "      <th>start_dt</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.036000e+06</td>\n",
       "      <td>1.387847e+06</td>\n",
       "      <td>489817.000000</td>\n",
       "      <td>4.036207e+06</td>\n",
       "      <td>4.036207e+06</td>\n",
       "      <td>3.594589e+06</td>\n",
       "      <td>3.621371e+06</td>\n",
       "      <td>3.621371e+06</td>\n",
       "      <td>4.036207e+06</td>\n",
       "      <td>4.036207e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.036207e+06</td>\n",
       "      <td>4.036207e+06</td>\n",
       "      <td>4.036207e+06</td>\n",
       "      <td>4.036207e+06</td>\n",
       "      <td>4.036207e+06</td>\n",
       "      <td>4.036207e+06</td>\n",
       "      <td>225917.000000</td>\n",
       "      <td>4036207</td>\n",
       "      <td>454277</td>\n",
       "      <td>4.036207e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.252137e-05</td>\n",
       "      <td>1.327218e-04</td>\n",
       "      <td>-0.000607</td>\n",
       "      <td>-1.432685e-04</td>\n",
       "      <td>1.383396e-04</td>\n",
       "      <td>3.266359e-04</td>\n",
       "      <td>-2.585168e-04</td>\n",
       "      <td>-3.262011e-04</td>\n",
       "      <td>7.910570e-05</td>\n",
       "      <td>1.383396e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.570352e+00</td>\n",
       "      <td>1.987750e+00</td>\n",
       "      <td>1.641676e+00</td>\n",
       "      <td>7.609392e-01</td>\n",
       "      <td>5.557003e+00</td>\n",
       "      <td>1.125505e-01</td>\n",
       "      <td>1.506301</td>\n",
       "      <td>2023-11-06 06:21:45.347923456</td>\n",
       "      <td>2023-11-17 00:42:24.480867072</td>\n",
       "      <td>2.938724e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.560081e-04</td>\n",
       "      <td>-2.522225e+00</td>\n",
       "      <td>-0.592014</td>\n",
       "      <td>-9.858535e-01</td>\n",
       "      <td>-1.145865e+00</td>\n",
       "      <td>-1.657011e+00</td>\n",
       "      <td>-1.318104e+00</td>\n",
       "      <td>-5.241477e+00</td>\n",
       "      <td>-1.152100e+00</td>\n",
       "      <td>-1.145865e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2022-04-19 06:50:05</td>\n",
       "      <td>2022-04-28 21:26:55</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.505928e-04</td>\n",
       "      <td>-7.846653e-01</td>\n",
       "      <td>-0.462179</td>\n",
       "      <td>-6.870721e-01</td>\n",
       "      <td>-3.406587e-01</td>\n",
       "      <td>-3.890285e-01</td>\n",
       "      <td>-8.330510e-01</td>\n",
       "      <td>-6.292958e-01</td>\n",
       "      <td>-7.512400e-01</td>\n",
       "      <td>-3.406587e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2023-06-03 18:37:20</td>\n",
       "      <td>2023-06-25 21:29:29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-7.488827e-04</td>\n",
       "      <td>8.411442e-02</td>\n",
       "      <td>-0.267427</td>\n",
       "      <td>-3.209154e-01</td>\n",
       "      <td>1.769741e-01</td>\n",
       "      <td>4.261034e-01</td>\n",
       "      <td>-8.342338e-02</td>\n",
       "      <td>-1.071620e-01</td>\n",
       "      <td>-2.167598e-01</td>\n",
       "      <td>1.769741e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2023-11-22 08:52:46</td>\n",
       "      <td>2023-12-11 09:15:12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-7.448212e-04</td>\n",
       "      <td>9.528942e-01</td>\n",
       "      <td>0.057159</td>\n",
       "      <td>5.080537e-01</td>\n",
       "      <td>1.769741e-01</td>\n",
       "      <td>4.261034e-01</td>\n",
       "      <td>1.195353e+00</td>\n",
       "      <td>6.760386e-01</td>\n",
       "      <td>5.181504e-01</td>\n",
       "      <td>1.769741e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2024-04-27 15:37:10.500000</td>\n",
       "      <td>2024-04-25 05:45:35</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.339736e+03</td>\n",
       "      <td>9.528942e-01</td>\n",
       "      <td>5.899720</td>\n",
       "      <td>1.141358e+01</td>\n",
       "      <td>8.804188e+00</td>\n",
       "      <td>1.401163e+01</td>\n",
       "      <td>7.412853e+00</td>\n",
       "      <td>5.636309e+00</td>\n",
       "      <td>9.938363e+00</td>\n",
       "      <td>8.804188e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.520000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>2024-11-01 22:38:54</td>\n",
       "      <td>2024-11-02 07:49:56</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.431024e-01</td>\n",
       "      <td>9.999002e-01</td>\n",
       "      <td>0.997373</td>\n",
       "      <td>1.000089e+00</td>\n",
       "      <td>1.000341e+00</td>\n",
       "      <td>1.001271e+00</td>\n",
       "      <td>9.997053e-01</td>\n",
       "      <td>9.999505e-01</td>\n",
       "      <td>1.000235e+00</td>\n",
       "      <td>1.000341e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.683009e-01</td>\n",
       "      <td>1.419784e-01</td>\n",
       "      <td>9.512670e-01</td>\n",
       "      <td>4.265100e-01</td>\n",
       "      <td>8.201449e+00</td>\n",
       "      <td>3.160425e-01</td>\n",
       "      <td>1.430518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.555343e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       monthly_income  work_experience  requested_sum  main_agreement_amount  \\\n",
       "count    4.036000e+06     1.387847e+06  489817.000000           4.036207e+06   \n",
       "mean    -8.252137e-05     1.327218e-04      -0.000607          -1.432685e-04   \n",
       "min     -7.560081e-04    -2.522225e+00      -0.592014          -9.858535e-01   \n",
       "25%     -7.505928e-04    -7.846653e-01      -0.462179          -6.870721e-01   \n",
       "50%     -7.488827e-04     8.411442e-02      -0.267427          -3.209154e-01   \n",
       "75%     -7.448212e-04     9.528942e-01       0.057159           5.080537e-01   \n",
       "max      1.339736e+03     9.528942e-01       5.899720           1.141358e+01   \n",
       "std      9.431024e-01     9.999002e-01       0.997373           1.000089e+00   \n",
       "\n",
       "       main_agreement_term  requested_period_days  requested_amount  \\\n",
       "count         4.036207e+06           3.594589e+06      3.621371e+06   \n",
       "mean          1.383396e-04           3.266359e-04     -2.585168e-04   \n",
       "min          -1.145865e+00          -1.657011e+00     -1.318104e+00   \n",
       "25%          -3.406587e-01          -3.890285e-01     -8.330510e-01   \n",
       "50%           1.769741e-01           4.261034e-01     -8.342338e-02   \n",
       "75%           1.769741e-01           4.261034e-01      1.195353e+00   \n",
       "max           8.804188e+00           1.401163e+01      7.412853e+00   \n",
       "std           1.000341e+00           1.001271e+00      9.997053e-01   \n",
       "\n",
       "       req_app_amount  approved_amount   period_days  ...     interface  \\\n",
       "count    3.621371e+06     4.036207e+06  4.036207e+06  ...  4.036207e+06   \n",
       "mean    -3.262011e-04     7.910570e-05  1.383396e-04  ...  1.570352e+00   \n",
       "min     -5.241477e+00    -1.152100e+00 -1.145865e+00  ...  0.000000e+00   \n",
       "25%     -6.292958e-01    -7.512400e-01 -3.406587e-01  ...  1.000000e+00   \n",
       "50%     -1.071620e-01    -2.167598e-01  1.769741e-01  ...  2.000000e+00   \n",
       "75%      6.760386e-01     5.181504e-01  1.769741e-01  ...  2.000000e+00   \n",
       "max      5.636309e+00     9.938363e+00  8.804188e+00  ...  2.000000e+00   \n",
       "std      9.999505e-01     1.000235e+00  1.000341e+00  ...  7.683009e-01   \n",
       "\n",
       "               type  repayment_type   client_type    loan_order  \\\n",
       "count  4.036207e+06    4.036207e+06  4.036207e+06  4.036207e+06   \n",
       "mean   1.987750e+00    1.641676e+00  7.609392e-01  5.557003e+00   \n",
       "min    0.000000e+00    0.000000e+00  0.000000e+00  1.000000e+00   \n",
       "25%    2.000000e+00    1.000000e+00  1.000000e+00  2.000000e+00   \n",
       "50%    2.000000e+00    1.000000e+00  1.000000e+00  3.000000e+00   \n",
       "75%    2.000000e+00    2.000000e+00  1.000000e+00  7.000000e+00   \n",
       "max    3.000000e+00    3.000000e+00  1.000000e+00  3.520000e+02   \n",
       "std    1.419784e-01    9.512670e-01  4.265100e-01  8.201449e+00   \n",
       "\n",
       "       have_extension  contact_cases                     created_at  \\\n",
       "count    4.036207e+06  225917.000000                        4036207   \n",
       "mean     1.125505e-01       1.506301  2023-11-06 06:21:45.347923456   \n",
       "min      0.000000e+00       1.000000            2022-04-19 06:50:05   \n",
       "25%      0.000000e+00       1.000000            2023-06-03 18:37:20   \n",
       "50%      0.000000e+00       1.000000            2023-11-22 08:52:46   \n",
       "75%      0.000000e+00       1.000000     2024-04-27 15:37:10.500000   \n",
       "max      1.000000e+00      64.000000            2024-11-01 22:38:54   \n",
       "std      3.160425e-01       1.430518                            NaN   \n",
       "\n",
       "                            start_dt         churn  \n",
       "count                         454277  4.036207e+06  \n",
       "mean   2023-11-17 00:42:24.480867072  2.938724e-01  \n",
       "min              2022-04-28 21:26:55  0.000000e+00  \n",
       "25%              2023-06-25 21:29:29  0.000000e+00  \n",
       "50%              2023-12-11 09:15:12  0.000000e+00  \n",
       "75%              2024-04-25 05:45:35  1.000000e+00  \n",
       "max              2024-11-02 07:49:56  1.000000e+00  \n",
       "std                              NaN  4.555343e-01  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3d1f1563-9e35-4b3b-b94a-d0df88946deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>work_experience</th>\n",
       "      <th>requested_sum</th>\n",
       "      <th>main_agreement_amount</th>\n",
       "      <th>main_agreement_term</th>\n",
       "      <th>requested_period_days</th>\n",
       "      <th>requested_amount</th>\n",
       "      <th>req_app_amount</th>\n",
       "      <th>approved_amount</th>\n",
       "      <th>period_days</th>\n",
       "      <th>...</th>\n",
       "      <th>client_type</th>\n",
       "      <th>settlement</th>\n",
       "      <th>region</th>\n",
       "      <th>gender</th>\n",
       "      <th>loan_order</th>\n",
       "      <th>have_extension</th>\n",
       "      <th>contact_cases</th>\n",
       "      <th>created_at</th>\n",
       "      <th>start_dt</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000735</td>\n",
       "      <td>0.952894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.388291</td>\n",
       "      <td>-0.340659</td>\n",
       "      <td>-0.389028</td>\n",
       "      <td>-1.053530</td>\n",
       "      <td>-0.629296</td>\n",
       "      <td>-0.61762</td>\n",
       "      <td>-0.340659</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>г Москва</td>\n",
       "      <td>г Москва</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-23 17:50:25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000742</td>\n",
       "      <td>0.952894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.388291</td>\n",
       "      <td>-1.145865</td>\n",
       "      <td>-1.294731</td>\n",
       "      <td>-0.436189</td>\n",
       "      <td>-0.020140</td>\n",
       "      <td>-0.61762</td>\n",
       "      <td>-1.145865</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>г Москва</td>\n",
       "      <td>г Москва</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-06-29 22:26:08</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000742</td>\n",
       "      <td>0.952894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.388291</td>\n",
       "      <td>-0.685747</td>\n",
       "      <td>-1.113590</td>\n",
       "      <td>-0.259806</td>\n",
       "      <td>0.153905</td>\n",
       "      <td>-0.61762</td>\n",
       "      <td>-0.685747</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>г Пермь</td>\n",
       "      <td>край Пермский</td>\n",
       "      <td>male</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-10 21:06:38</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000742</td>\n",
       "      <td>0.952894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.388291</td>\n",
       "      <td>0.176974</td>\n",
       "      <td>-1.385301</td>\n",
       "      <td>1.239449</td>\n",
       "      <td>1.633284</td>\n",
       "      <td>-0.61762</td>\n",
       "      <td>0.176974</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>г Самара</td>\n",
       "      <td>обл Самарская</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-01 00:13:16</td>\n",
       "      <td>2024-01-12 17:29:21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000742</td>\n",
       "      <td>0.952894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.388291</td>\n",
       "      <td>-1.145865</td>\n",
       "      <td>-1.657011</td>\n",
       "      <td>0.357534</td>\n",
       "      <td>0.763061</td>\n",
       "      <td>-0.61762</td>\n",
       "      <td>-1.145865</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>г Москва</td>\n",
       "      <td>г Москва</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-15 10:40:35</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   monthly_income  work_experience  requested_sum  main_agreement_amount  \\\n",
       "0       -0.000735         0.952894            NaN              -0.388291   \n",
       "1       -0.000742         0.952894            NaN              -0.388291   \n",
       "2       -0.000742         0.952894            NaN              -0.388291   \n",
       "3       -0.000742         0.952894            NaN              -0.388291   \n",
       "4       -0.000742         0.952894            NaN              -0.388291   \n",
       "\n",
       "   main_agreement_term  requested_period_days  requested_amount  \\\n",
       "0            -0.340659              -0.389028         -1.053530   \n",
       "1            -1.145865              -1.294731         -0.436189   \n",
       "2            -0.685747              -1.113590         -0.259806   \n",
       "3             0.176974              -1.385301          1.239449   \n",
       "4            -1.145865              -1.657011          0.357534   \n",
       "\n",
       "   req_app_amount  approved_amount  period_days  ...  client_type  settlement  \\\n",
       "0       -0.629296         -0.61762    -0.340659  ...            1    г Москва   \n",
       "1       -0.020140         -0.61762    -1.145865  ...            1    г Москва   \n",
       "2        0.153905         -0.61762    -0.685747  ...            1     г Пермь   \n",
       "3        1.633284         -0.61762     0.176974  ...            1    г Самара   \n",
       "4        0.763061         -0.61762    -1.145865  ...            1    г Москва   \n",
       "\n",
       "          region  gender  loan_order  have_extension  contact_cases  \\\n",
       "0       г Москва    male           2               0            NaN   \n",
       "1       г Москва  female          14               0            NaN   \n",
       "2  край Пермский    male          10               0            NaN   \n",
       "3  обл Самарская  female           2               1            NaN   \n",
       "4       г Москва  female          17               0            NaN   \n",
       "\n",
       "           created_at            start_dt  churn  \n",
       "0 2022-12-23 17:50:25                 NaT      0  \n",
       "1 2024-06-29 22:26:08                 NaT      0  \n",
       "2 2023-04-10 21:06:38                 NaT      0  \n",
       "3 2023-10-01 00:13:16 2024-01-12 17:29:21      0  \n",
       "4 2024-07-15 10:40:35                 NaT      0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0931a8-cb6a-4ba9-a50b-14633db813ac",
   "metadata": {},
   "source": [
    "#### Дубли и пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "927fd3a4-500b-400a-81f5-2830f63f03f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество дубликатов: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Количество дубликатов: {train.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ce276a26-0da5-4b25-a3fe-e9b4532f05c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "monthly_income            0.005129\n",
       "work_experience          65.615069\n",
       "requested_sum            87.864423\n",
       "main_agreement_amount     0.000000\n",
       "main_agreement_term       0.000000\n",
       "requested_period_days    10.941411\n",
       "requested_amount         10.277867\n",
       "req_app_amount           10.277867\n",
       "approved_amount           0.000000\n",
       "period_days               0.000000\n",
       "days_finish_loan          0.000000\n",
       "ag                        0.000000\n",
       "cnt_ext                  88.760462\n",
       "term                     88.760462\n",
       "price                    88.766904\n",
       "elecs_sum                 0.143551\n",
       "recurents_sum             0.143551\n",
       "tamount                   0.043952\n",
       "issues                    0.000000\n",
       "principal                 0.000000\n",
       "interest                  0.000000\n",
       "overdue_interest          0.000000\n",
       "overdue_fee               0.000000\n",
       "nbki_score                2.092955\n",
       "payment_frequency         0.000000\n",
       "status                    0.000000\n",
       "loan_id                   0.000000\n",
       "client_id                 0.000000\n",
       "source                    0.000000\n",
       "first_source              0.000000\n",
       "interface                 0.000000\n",
       "type                      0.000000\n",
       "repayment_type            0.000000\n",
       "client_type               0.000000\n",
       "settlement                0.000000\n",
       "region                    0.000000\n",
       "gender                    0.000000\n",
       "loan_order                0.000000\n",
       "have_extension            0.000000\n",
       "contact_cases            94.402740\n",
       "created_at                0.000000\n",
       "start_dt                 88.744953\n",
       "churn                     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пропуски в %\n",
    "train.isnull().sum()/len(train)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb62b5-c67f-4a1f-9497-a10c178edbd6",
   "metadata": {},
   "source": [
    "Отличились следующие фичи:\n",
    "- work_experience - стаж - 65% пропусков\n",
    "- requested_sum - запрашиваемая сумма клиента для займа - 88% пропусков\n",
    "- cnt_ext - кол-во пролонгаций по займу - 89% пропусков\n",
    "- term - срок пролонгации (список) - 89% пропусков\n",
    "- price -  цена пролонгации (список) - 89% пропусков\n",
    "- contact_cases - кол-во обращений клиента с коллекшн - 94% пропусков\n",
    "- start_dt  -  дата начала (список) пролонгаций по займу - 89% пропусков\n",
    "\n",
    "\n",
    "Пропуски необходимо обработать, поэтому заполним их 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "68c8eb78-6160-451a-b170-7cded4babd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['monthly_income', 'work_experience', 'requested_sum', 'requested_period_days', 'requested_amount', 'req_app_amount', 'cnt_ext', 'term', 'price', 'elecs_sum', 'recurents_sum', 'tamount', 'nbki_score', 'contact_cases', 'start_dt']\n"
     ]
    }
   ],
   "source": [
    "# получим список столбцов с пропущенными значениями\n",
    "nans = train.columns[train.isnull().any()].tolist()\n",
    "print(nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "47d35376-fd5a-4260-998d-49d00774f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4036207 entries, 0 to 4036206\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   monthly_income         float32       \n",
      " 1   work_experience        float32       \n",
      " 2   requested_sum          float32       \n",
      " 3   requested_period_days  float32       \n",
      " 4   requested_amount       float32       \n",
      " 5   req_app_amount         float32       \n",
      " 6   cnt_ext                float32       \n",
      " 7   term                   float32       \n",
      " 8   price                  float32       \n",
      " 9   elecs_sum              float32       \n",
      " 10  recurents_sum          float32       \n",
      " 11  tamount                float32       \n",
      " 12  nbki_score             float32       \n",
      " 13  contact_cases          float32       \n",
      " 14  start_dt               datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float32(14)\n",
      "memory usage: 246.4 MB\n"
     ]
    }
   ],
   "source": [
    "# 'start_dt' необходимо обработать отдельно\n",
    "train[nans].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d165fa2e-b918-4b65-9204-38483bd66613",
   "metadata": {},
   "outputs": [],
   "source": [
    "nans.remove('start_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "392c43b2-588f-4438-a778-a6d299c4eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[nans] = train[nans].fillna(0)\n",
    "test[nans] = test[nans].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6c822929-7506-4315-9c0b-24044b2871b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# колонку с пропуском даты обработаем сегодняшней датой!\n",
    "train['start_dt'].fillna(datetime.now(), inplace=True)\n",
    "test['start_dt'].fillna(datetime.now(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "651409db-7e5b-4785-b54c-a0f736886178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "monthly_income           0.0\n",
       "work_experience          0.0\n",
       "requested_sum            0.0\n",
       "main_agreement_amount    0.0\n",
       "main_agreement_term      0.0\n",
       "requested_period_days    0.0\n",
       "requested_amount         0.0\n",
       "req_app_amount           0.0\n",
       "approved_amount          0.0\n",
       "period_days              0.0\n",
       "days_finish_loan         0.0\n",
       "ag                       0.0\n",
       "cnt_ext                  0.0\n",
       "term                     0.0\n",
       "price                    0.0\n",
       "elecs_sum                0.0\n",
       "recurents_sum            0.0\n",
       "tamount                  0.0\n",
       "issues                   0.0\n",
       "principal                0.0\n",
       "interest                 0.0\n",
       "overdue_interest         0.0\n",
       "overdue_fee              0.0\n",
       "nbki_score               0.0\n",
       "payment_frequency        0.0\n",
       "status                   0.0\n",
       "loan_id                  0.0\n",
       "client_id                0.0\n",
       "source                   0.0\n",
       "first_source             0.0\n",
       "interface                0.0\n",
       "type                     0.0\n",
       "repayment_type           0.0\n",
       "client_type              0.0\n",
       "settlement               0.0\n",
       "region                   0.0\n",
       "gender                   0.0\n",
       "loan_order               0.0\n",
       "have_extension           0.0\n",
       "contact_cases            0.0\n",
       "created_at               0.0\n",
       "start_dt                 0.0\n",
       "churn                    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пропуски в %\n",
    "train.isnull().sum()/len(train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3dee523e-d6c1-4e74-bb50-b5faca93f315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "monthly_income           0.0\n",
       "work_experience          0.0\n",
       "requested_sum            0.0\n",
       "main_agreement_amount    0.0\n",
       "main_agreement_term      0.0\n",
       "requested_period_days    0.0\n",
       "requested_amount         0.0\n",
       "req_app_amount           0.0\n",
       "approved_amount          0.0\n",
       "period_days              0.0\n",
       "days_finish_loan         0.0\n",
       "ag                       0.0\n",
       "cnt_ext                  0.0\n",
       "term                     0.0\n",
       "price                    0.0\n",
       "elecs_sum                0.0\n",
       "recurents_sum            0.0\n",
       "tamount                  0.0\n",
       "issues                   0.0\n",
       "principal                0.0\n",
       "interest                 0.0\n",
       "overdue_interest         0.0\n",
       "overdue_fee              0.0\n",
       "nbki_score               0.0\n",
       "payment_frequency        0.0\n",
       "status                   0.0\n",
       "loan_id                  0.0\n",
       "client_id                0.0\n",
       "source                   0.0\n",
       "first_source             0.0\n",
       "interface                0.0\n",
       "type                     0.0\n",
       "repayment_type           0.0\n",
       "client_type              0.0\n",
       "settlement               0.0\n",
       "region                   0.0\n",
       "gender                   0.0\n",
       "loan_order               0.0\n",
       "have_extension           0.0\n",
       "contact_cases            0.0\n",
       "created_at               0.0\n",
       "start_dt                 0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пропуски в %\n",
    "test.isnull().sum()/len(train)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45b6c42-321d-4fae-884e-35cfe5b4791c",
   "metadata": {},
   "source": [
    "#### DataClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f0b6b73a-6660-46f8-a554-46256b527e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleanerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, region_column=None, region_reference=None):\n",
    "        self.missing_cols = []\n",
    "        self.region_column = region_column\n",
    "        self.region_reference = region_reference\n",
    "        self.reference_list = []\n",
    "        self.label_encoders = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Сохраняем список колонок с пропущенными значениями для добавления индикаторов\n",
    "        self.missing_cols = X.columns[X.isnull().any()].tolist()\n",
    "\n",
    "        if self.region_column and self.region_reference:\n",
    "            reference = pd.read_csv(self.region_reference)\n",
    "            reference[\"region_name\"] = reference[\"region_name\"].str.lower().str.strip()\n",
    "            self.reference_list = reference[\"region_name\"].tolist()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = X.copy()\n",
    "        \n",
    "        # Добавляем индикаторы пропущенных значений перед заполнением пропусков\n",
    "        data = self.add_missing_indicators(data)\n",
    "\n",
    "        # Применяем функции для заполнения пропущенных значений\n",
    "        data = self.fill_monthly_income(data)\n",
    "        data = self.fill_work_experience(data)\n",
    "        data = self.fill_requested_sum(data)\n",
    "        data = self.fill_requested_amount_and_req_app_amount(data)\n",
    "        data = self.fill_requested_period_days(data)\n",
    "        data = self.fill_term_and_price(data)\n",
    "        data = self.fill_elecs_sum_and_recurents_sum(data)\n",
    "        data = self.fill_tamount(data)\n",
    "        data = self.fill_nbki_score(data)\n",
    "        data = self.fill_cnt_ext(data)\n",
    "        data = self.fill_start_dt(data)\n",
    "        data = self.fill_contact_cases(data)\n",
    "\n",
    "        if self.region_column:\n",
    "            data[self.region_column] = data[self.region_column].str.lower().str.strip()\n",
    "            data[self.region_column] = data[self.region_column].apply(self.find_closest_match)\n",
    "\n",
    "        data = self.process_settlement(data)\n",
    "\n",
    "        # Генерация новых признаков\n",
    "        data = self.generate_features(data)\n",
    "\n",
    "        # Обработка дат\n",
    "        data = self.process_dates(data)\n",
    "\n",
    "        # Преобразование категориальных переменных\n",
    "        data = self.encode_categorical_features(data)\n",
    "\n",
    "        # Удаление ненужных признаков\n",
    "        data = self.delete_bad_features(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def fill_monthly_income(self, data):\n",
    "        data['monthly_income'] = data.groupby('status')['monthly_income'].transform(\n",
    "            lambda x: x.fillna(x.median()) if not np.isnan(x.median()) else x.fillna(data['monthly_income'].median())\n",
    "        )\n",
    "        return data\n",
    "\n",
    "    def fill_work_experience(self, data):\n",
    "        data['work_experience'] = data.groupby('status')['work_experience'].transform(\n",
    "            lambda x: x.fillna(x.median()) if not np.isnan(x.median()) else x.fillna(data['work_experience'].median())\n",
    "        )\n",
    "        return data\n",
    "\n",
    "    def fill_requested_sum(self, data):\n",
    "        data['requested_sum'] = data['requested_sum'].fillna(\n",
    "            data['approved_amount'] * (data['requested_sum'].median() / data['approved_amount'].median())\n",
    "        )\n",
    "        return data\n",
    "\n",
    "    def fill_requested_amount_and_req_app_amount(self, data):\n",
    "        data['requested_amount'] = data['requested_amount'].fillna(data['requested_sum'])\n",
    "        data['req_app_amount'] = data['requested_amount'] - data['approved_amount']\n",
    "        return data\n",
    "\n",
    "    def fill_requested_period_days(self, data):\n",
    "        data['requested_period_days'] = data.groupby('type')['requested_period_days'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        return data\n",
    "\n",
    "    def fill_term_and_price(self, data):\n",
    "        data['term'] = data['term'].fillna(0)\n",
    "        data['price'] = data['price'].fillna(0)\n",
    "        return data\n",
    "\n",
    "    def fill_elecs_sum_and_recurents_sum(self, data):\n",
    "        data['elecs_sum'] = data.groupby('repayment_type')['elecs_sum'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        data['recurents_sum'] = data.groupby('repayment_type')['recurents_sum'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        return data\n",
    "\n",
    "    def fill_tamount(self, data):\n",
    "        data['tamount'] = data['tamount'].fillna(data['principal'] + data['interest'] + data['issues'])\n",
    "        return data\n",
    "\n",
    "    def fill_nbki_score(self, data):\n",
    "        data['nbki_score'] = data.groupby('status')['nbki_score'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        return data\n",
    "\n",
    "    def fill_cnt_ext(self, data):\n",
    "        data['cnt_ext'] = data['cnt_ext'].fillna(0)\n",
    "        return data\n",
    "\n",
    "    def add_missing_indicators(self, data):\n",
    "        for col in self.missing_cols:\n",
    "            data[f'{col}_missing'] = data[col].isnull().astype(int)\n",
    "        return data\n",
    "\n",
    "    def fill_contact_cases(self, data):\n",
    "        data['contact_cases'] = data.groupby('repayment_type')['contact_cases'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        data['contact_cases'] = data['contact_cases'].fillna(data['contact_cases'].median())\n",
    "        return data\n",
    "\n",
    "    def fill_start_dt(self, data):\n",
    "        data['start_dt'] = pd.to_datetime(data['start_dt'], errors='coerce')\n",
    "        data['start_dt'] = data.groupby('client_id')['start_dt'].transform(\n",
    "            lambda x: x.fillna(x.min())\n",
    "        )\n",
    "        data['start_dt'] = data['start_dt'].fillna(data['created_at'])\n",
    "        return data\n",
    "\n",
    "    def find_closest_match(self, region):\n",
    "        match = process.extractOne(region, self.reference_list, scorer=fuzz.ratio)\n",
    "        return match[0] if match and match[1] >= 60 else region  # Минимальный порог схожести - 60%\n",
    "\n",
    "    def generate_features(self, data):\n",
    "        # Платежное поведение\n",
    "        data['payment_to_income_ratio'] = data['tamount'] / data['monthly_income']\n",
    "        data['interest_to_principal_ratio'] = data['interest'] / data['principal']\n",
    "        data['overdue_ratio'] = (data['overdue_interest'] + data['overdue_fee']) / data['principal']\n",
    "\n",
    "        # Временные характеристики\n",
    "        data['early_repayment'] = data['period_days'] - data['days_finish_loan']\n",
    "\n",
    "        # Кредитное поведение\n",
    "        data['approval_ratio'] = data['approved_amount'] / data['requested_amount']\n",
    "        data['previous_extensions'] = data['cnt_ext'].fillna(0)\n",
    "        data['had_extensions'] = data['cnt_ext'].notna().astype(int)\n",
    "\n",
    "        # Признаки рискованности клиента\n",
    "        data['risk_score'] = (\n",
    "            (data['nbki_score'] * -1) +  # Инвертируем скор, чтобы высокие значения означали высокий риск\n",
    "            (data['overdue_ratio'] * 2) +\n",
    "            (data['had_extensions'] * 1.5)\n",
    "        )\n",
    "\n",
    "        # Поведенческие признаки\n",
    "        data['digital_engagement'] = ((data['interface'] == 2) |\n",
    "                                        (data['source'].isin([11, 12]))).astype(int)\n",
    "        data['prefers_longer_terms'] = (data['requested_period_days'] > \n",
    "                                          data['requested_period_days'].mean()).astype(int)\n",
    "\n",
    "        # Группируем по client_id и создаем новые признаки\n",
    "        client_features = data.groupby('client_id').agg({\n",
    "            'loan_id': 'count',  # Общее количество займов\n",
    "            'days_finish_loan': 'mean',  # Средний срок закрытия займа\n",
    "            'approved_amount': 'mean',  # Средняя сумма займа\n",
    "            'cnt_ext': 'sum',  # Общее количество продлений\n",
    "            'elecs_sum': 'sum',  # Сумма штрафов\n",
    "            'created_at': 'max',  # Дата последнего займа\n",
    "            'monthly_income': 'std',  # Вариация дохода\n",
    "            'contact_cases': 'sum'  # Количество обращений в поддержку\n",
    "        }).reset_index()\n",
    "\n",
    "        client_features.rename(columns={\n",
    "            'loan_id': 'total_loans',\n",
    "            'days_finish_loan': 'avg_days_finish_loan',\n",
    "            'approved_amount': 'avg_approved_amount',\n",
    "            'cnt_ext': 'total_extensions',\n",
    "            'elecs_sum': 'total_fees',\n",
    "            'created_at': 'last_loan_date',\n",
    "            'monthly_income': 'income_variation',\n",
    "            'contact_cases': 'total_contacts'\n",
    "        }, inplace=True)\n",
    "        data = data.merge(client_features, on='client_id', how='left')\n",
    "        \n",
    "        # Финансовая нагрузка\n",
    "        data['total_debt_burden'] = (data['elecs_sum'] + data['recurents_sum']) / data['monthly_income']\n",
    "        data['disposable_income_ratio'] = 1 - data['total_debt_burden']\n",
    "\n",
    "        return data\n",
    "\n",
    "    def process_dates(self, data):\n",
    "        date_columns = ['created_at', 'closed_at', 'start_dt']\n",
    "        for col in date_columns:\n",
    "            if col in data.columns:\n",
    "                data[col] = pd.to_datetime(data[col], errors='coerce')  # Преобразуем в datetime\n",
    "                data[col] = data[col].fillna(data['start_dt'])  # Заполняем отсутствующие значения датой из 'start_dt'\n",
    "                # Преобразуем datetime в формат timestamp (количество секунд с начала эпохи)\n",
    "                data[col] = data[col].astype('int64') // 10**9\n",
    "        return data\n",
    "\n",
    "    def encode_categorical_features(self, data):\n",
    "        categorical_features = ['status', 'payment_frequency', 'source', 'first_source', \n",
    "                                'interface', 'type', 'repayment_type', 'settlement', 'client_type.1', 'region', 'gender']\n",
    "\n",
    "        for feature in categorical_features:\n",
    "            data[feature] = data[feature].astype(str).fillna(\"missing\")  # Используем строку, чтобы избежать ошибки\n",
    "            le = LabelEncoder()\n",
    "            data[feature] = le.fit_transform(data[feature])\n",
    "            self.label_encoders[feature] = le\n",
    "\n",
    "        return data\n",
    "\n",
    "    def clean_city_name(self, name):\n",
    "        # Извлечение последнего слова\n",
    "        name = name.split()[-1].lower().strip()\n",
    "        # Удаление нежелательных символов (всего, что не буквы и не цифры)\n",
    "        name = re.sub(r'[^а-яa-z0-9]', '', name)\n",
    "        \n",
    "        return name\n",
    "\n",
    "    def process_settlement(self, data):\n",
    "        data['settlement'] = data['settlement'].apply(self.clean_city_name)\n",
    "        threshold = 400\n",
    "        data_region_counts = data['settlement'].value_counts()\n",
    "        data['settlement'] = data['settlement'].apply(lambda x: x if data_region_counts[x] > threshold else 'другие')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def delete_bad_features(self, data):\n",
    "        columns = ['loan_id', 'client_id']\n",
    "        data.drop(columns=columns, inplace=True)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9bc4adb7-f839-4a9e-a368-ba5eb4fc765b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/region-reference/region_reference.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m transformer \u001b[38;5;241m=\u001b[39m DataCleanerTransformer(\n\u001b[1;32m      4\u001b[0m     region_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m\"\u001b[39m, region_reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/region-reference/region_reference.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Файл region_reference содержит правильно написанные названия регионов, исправление работает, так что, находятся \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ближайше возможные записи из region_reference и по ним заменяются записи из train и test\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m test \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(test)\n\u001b[1;32m     12\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/media/talium/1DA5AE943A305AF1/DataSciense/Projects/PetProjects/ClassicML/01.A-Money/Classicenv/lib/python3.10/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m/media/talium/1DA5AE943A305AF1/DataSciense/Projects/PetProjects/ClassicML/01.A-Money/Classicenv/lib/python3.10/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    903\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    904\u001b[0m             (\n\u001b[1;32m    905\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    914\u001b[0m         )\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "Cell \u001b[0;32mIn[126], line 14\u001b[0m, in \u001b[0;36mDataCleanerTransformer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_cols \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns[X\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39many()]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregion_column \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregion_reference:\n\u001b[0;32m---> 14\u001b[0m     reference \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregion_reference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     reference[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregion_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m reference[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregion_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_list \u001b[38;5;241m=\u001b[39m reference[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregion_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/media/talium/1DA5AE943A305AF1/DataSciense/Projects/PetProjects/ClassicML/01.A-Money/Classicenv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/talium/1DA5AE943A305AF1/DataSciense/Projects/PetProjects/ClassicML/01.A-Money/Classicenv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/media/talium/1DA5AE943A305AF1/DataSciense/Projects/PetProjects/ClassicML/01.A-Money/Classicenv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/talium/1DA5AE943A305AF1/DataSciense/Projects/PetProjects/ClassicML/01.A-Money/Classicenv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/media/talium/1DA5AE943A305AF1/DataSciense/Projects/PetProjects/ClassicML/01.A-Money/Classicenv/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/region-reference/region_reference.csv'"
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    "start_time = time.time()\n",
    "transformer = DataCleanerTransformer(\n",
    "    region_column=\"region\", region_reference=\"/kaggle/input/region-reference/region_reference.csv\"\n",
    ")\n",
    "# Файл region_reference содержит правильно написанные названия регионов, исправление работает, так что, находятся \n",
    "# ближайше возможные записи из region_reference и по ним заменяются записи из train и test\n",
    "\n",
    "train = transformer.fit_transform(train)\n",
    "test = transformer.fit_transform(test)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = round(end_time - start_time, 2)\n",
    "print(f\"\\nElapsed Time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c39560-e513-4c8e-851f-fd12e80e8923",
   "metadata": {},
   "source": [
    "Определим класс для предобработки данных, который выполняет:\n",
    "\n",
    "- Очистку текстовых признаков:\n",
    "— Для столбцов, таких как region и settlement, производится нормализация, удаление лишних слов (например, «область», «край» и т.д.) и спецсимволов, а также устранение дублирования слов.\n",
    "— Для столбца settlement дополнительно создаётся новый признак settlement_category, определяемый с помощью регулярных выражений, классифицирующих тип населённого пункта (город, поселок городского типа, село).\n",
    "\n",
    "- Обработку временных признаков:\n",
    "— Из столбца created_at извлекаются базовые временные признаки, такие как месяц создания займа и день недели.\n",
    "— При группировке по client_id вычисляются промежутки времени между займами, количество займов, а также производные признаки, такие как время с первого или до последнего займа и частота займов.\n",
    "\n",
    "- Обработку финансовых признаков:\n",
    "— Рассчитывается коэффициент, отношение одобренной суммы к запрашиваемой (approved_requested_ratio), что позволяет выявлять финансовые аномалии и соотношения.\n",
    "\n",
    "- Обработку пропусков:\n",
    "— Пропущенные значения в числовых признаках заполняются медианой (за исключением идентификаторов), что обеспечивает корректность дальнейшего анализа и моделирования.\n",
    "\n",
    "- Кодирование категориальных признаков:\n",
    "— Для признаков с небольшим числом уникальных значений применяется one-hot кодирование (с использованием OneHotEncoder), а для остальных — порядковое кодирование (OrdinalEncoder).\n",
    "— Кроме того, создаётся комбинированный признак status_client_type, объединяющий информацию из нескольких исходных столбцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f92dc5aa-bc62-4a05-9be2-ff3b2c95d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessorOptimized:\n",
    "    \"\"\"\n",
    "    Класс для предобработки данных.\n",
    "    Выполняет:\n",
    "      - Очистку текстовых признаков\n",
    "      - Обработку временных и финансовых признаков\n",
    "      - Обработка пропусков\n",
    "      - Кодирование категориальных признаков\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Инициализируем регулярные выражения и энкодеры\n",
    "        self._init_regex_patterns()\n",
    "        self._init_encoders()\n",
    "\n",
    "    def _init_regex_patterns(self):\n",
    "        \"\"\"\n",
    "        Инициализирует регулярные выражения для очистки текстовых признаков,\n",
    "        таких как 'region' и 'settlement'. Здесь задаются слова, которые необходимо удалить,\n",
    "        а также шаблоны для классификации населённых пунктов.\n",
    "        \"\"\"\n",
    "        remove_words = [\n",
    "            'обл', 'область', 'край', 'народная', 'респ', 'г',\n",
    "            'республика', 'аобл', 'район', 'ао', 'автономный округ',\n",
    "            'югра', 'якутия', 'кузбасс', 'алания', 'чувашия'\n",
    "        ]\n",
    "        self.pattern_remove_words = re.compile(r'\\b(?:' + '|'.join(remove_words) + r')\\b', re.I)\n",
    "        self.pattern_non_word = re.compile(r'[^\\w\\s]', re.I)\n",
    "        self.pattern_sakhalin = re.compile(r'\\bсахалин\\b', re.I)\n",
    "        # Шаблоны для определения типа населённого пункта:\n",
    "        # 2 – для поселков городского типа, 3 – для поселков/сел, 1 – для городов.\n",
    "        self.settlement_patterns = {\n",
    "            2: re.compile(r'\\b(пгт|посёлок городского типа|поселок городского типа)\\b', re.I),\n",
    "            3: re.compile(r'\\b(п|рп|поселок|посёлок|с|сп|село)\\b', re.I),\n",
    "            1: re.compile(r'\\b(г|город)\\b', re.I)\n",
    "        }\n",
    "\n",
    "    def _init_encoders(self):\n",
    "        \"\"\"\n",
    "        Инициализирует энкодеры для категориальных признаков:\n",
    "          - onehot_encoder для столбцов с небольшим числом уникальных значений.\n",
    "          - ordinal_encoder для остальных.\n",
    "        \"\"\"\n",
    "        self.onehot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "        self.ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "    def _process_text_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Обрабатывает текстовые признаки:\n",
    "          - Нормализует столбец 'region': приводит к нижнему регистру, удаляет лишние слова, спецсимволы,\n",
    "            убирает дублирование слов.\n",
    "          - Обрабатывает 'settlement': нормализует, создает категорию населённого пункта, а также\n",
    "            вычисляет региональную популярность и индикатор для Москвы/СПБ.\n",
    "        \"\"\"\n",
    "        # Обработка региона\n",
    "        if 'region' in df.columns:\n",
    "            df['region'] = (\n",
    "                df['region']\n",
    "                .str.lower()\n",
    "                .str.replace(self.pattern_remove_words, '', regex=True)\n",
    "                .str.replace(self.pattern_non_word, '', regex=True)\n",
    "                .str.replace(r'\\s+', ' ', regex=True)\n",
    "                .str.replace(self.pattern_sakhalin, 'сахалинская', regex=True)\n",
    "                .apply(lambda x: ' '.join(dict.fromkeys(x.split())))\n",
    "                .str.strip()\n",
    "            )\n",
    "\n",
    "        # Обработка признака settlement\n",
    "        if 'settlement' in df.columns:\n",
    "            s = df['settlement'].str.lower()\n",
    "            conditions = [\n",
    "                s.str.contains(self.settlement_patterns[2], regex=True),\n",
    "                s.str.contains(self.settlement_patterns[3], regex=True),\n",
    "                s.str.contains(self.settlement_patterns[1], regex=True)\n",
    "            ]\n",
    "            df['settlement_category'] = np.select(conditions, [2, 3, 1], default=4)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _process_time_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Обрабатывает временные признаки:\n",
    "          - Извлекает базовые признаки из 'created_at': created_month, created_dayofweek.\n",
    "          - Использует групповые преобразования (transform) для вычисления:\n",
    "              * time_between_loans: разница в днях между последовательными займами.\n",
    "              * time_between_loans_mean: среднее значение time_between_loans по клиенту.\n",
    "              * first_loan, last_loan, loan_count: минимальная и максимальная дата займа и количество займов.\n",
    "              * time_since_first_loan и time_since_last_loan: производные признаки.\n",
    "              * loan_frequency: частота займов.\n",
    "        \"\"\"\n",
    "        # Сортировка по client_id и created_at\n",
    "        df = df.sort_values(['client_id', 'created_at'])\n",
    "        # Вычисляем разницу по времени между займами для каждой группы\n",
    "        df['time_between_loans'] = df.groupby('client_id')['created_at'].diff().dt.days\n",
    "\n",
    "        # Группируем по всему DataFrame по 'client_id'\n",
    "        g = df.groupby('client_id')\n",
    "        # Агрегируем нужные столбцы\n",
    "        agg_df = g.agg({\n",
    "            'time_between_loans': 'mean',\n",
    "            'created_at': ['min', 'max'],\n",
    "            'loan_id': 'size'\n",
    "        }).reset_index()\n",
    "        # Приводим многоуровневый индекс столбцов к плоскому виду\n",
    "        agg_df.columns = ['client_id', 'time_between_loans_mean', 'first_loan', 'last_loan', 'loan_count']\n",
    "\n",
    "        # Объединяем агрегированные данные с исходным DataFrame\n",
    "        df = df.merge(agg_df, on='client_id', how='left')\n",
    "        df['time_since_first_loan'] = (df['created_at'] - df['first_loan']).dt.days\n",
    "        df['time_since_last_loan'] = (df['last_loan'] - df['created_at']).dt.days\n",
    "        df['loan_frequency'] = df['loan_count'] / (((df['last_loan'] - df['first_loan']).dt.days / 365) + 1e-6)\n",
    "        df.drop(columns=['first_loan', 'last_loan'], inplace=True)\n",
    "        # Базовые временные признаки\n",
    "        df['created_month'] = df['created_at'].dt.month\n",
    "        df['created_dayofweek'] = df['created_at'].dt.dayofweek\n",
    "        return df\n",
    "\n",
    "    def _process_financial_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Обрабатывает финансовые признаки:\n",
    "          - Вычисляет коэффициенты:\n",
    "                approved_requested_ratio,\n",
    "        \"\"\"\n",
    "\n",
    "        if 'approved_amount' in df.columns and 'requested_amount' in df.columns:\n",
    "            df['approved_requested_ratio'] = df['approved_amount'] / (df['requested_amount'] + 1e-6)\n",
    "        return df\n",
    "\n",
    "    def _handle_missing_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Заполняет пропуски медианой для всех числовых признаков, кроме идентификаторов.\n",
    "        \"\"\"\n",
    "        numeric_cols = df.select_dtypes(include=np.number).columns.difference(['client_id', 'loan_id'])\n",
    "        if not numeric_cols.empty:\n",
    "            medians = df[numeric_cols].median()\n",
    "            df[numeric_cols] = df[numeric_cols].fillna(medians)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _encode_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Кодирует категориальные признаки:\n",
    "          - Создает комбинированный признак 'status_client_type'.\n",
    "          - Для признаков с ≤10 уникальными значениями применяется one-hot кодирование; новые столбцы добавляются,\n",
    "            а исходные колонки остаются.\n",
    "          - Для остальных создается новый столбец с порядковым кодированием (с суффиксом '_ordinal').\n",
    "        \"\"\"\n",
    "        if 'status' in df.columns and 'client_type' in df.columns:\n",
    "            df['status_client_type'] = df['status'].astype(str) + \"_\" + df['client_type'].astype(str)\n",
    "            df['status_client_type'] = df['status_client_type'].astype('category')\n",
    "\n",
    "        cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        for col in cat_cols:\n",
    "            # Если в столбце мало уникальных значений, применяем one-hot кодирование\n",
    "            if df[col].nunique() <= 10:\n",
    "                self.onehot_encoder.fit(df[[col]])\n",
    "                encoded = self.onehot_encoder.transform(df[[col]])\n",
    "                new_cols = self.onehot_encoder.get_feature_names_out([col])\n",
    "                # Добавляем новые столбцы с закодированными признаками, исходный столбец остается\n",
    "                df = pd.concat([\n",
    "                    df,\n",
    "                    pd.DataFrame(encoded, columns=new_cols, index=df.index)\n",
    "                ], axis=1)\n",
    "            else:\n",
    "                # Для остальных создаем новый столбец с порядковым кодированием\n",
    "                df[col + '_ordinal'] = self.ordinal_encoder.fit_transform(df[[col]]).astype(np.int32)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Выполняет последовательную предобработку данных.\n",
    "        Шаги:\n",
    "          1. Обработка текстовых признаков (region, settlement).\n",
    "          2. Обработка временных признаков (создание базовых временных признаков и групповых статистик).\n",
    "          3. Обработка финансовых признаков (расчет коэффициентов и производных признаков).\n",
    "          4. Обработка пропусков (заполнение медианой).\n",
    "          5. Кодирование категориальных признаков.\n",
    "\n",
    "        После каждого шага вызывается сборщик мусора для оптимизации памяти.\n",
    "        \"\"\"\n",
    "        processing_steps = [\n",
    "            self._process_text_features,\n",
    "            self._process_time_features,\n",
    "            self._process_financial_features,\n",
    "            self._handle_missing_data,\n",
    "            self._encode_features,\n",
    "        ]\n",
    "\n",
    "        with tqdm(processing_steps, desc=\"Обработка данных\") as pbar:\n",
    "            for step in pbar:\n",
    "                df = step(df).copy()\n",
    "                pbar.set_postfix(shape=df.shape)\n",
    "                gc.collect()\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "08d40a2a-c800-466d-b5f7-8d32d38dffc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'compute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23353/3445024553.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataPreprocessorOptimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprocessed_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/talium/1DA5AE943A305AF1/DataSciense/Projects/PetProjects/ClassicML/01.A-Money/Classicenv/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'compute'"
     ]
    }
   ],
   "source": [
    "preprocessor = DataPreprocessorOptimized()\n",
    "processed_train = preprocessor.preprocess_data(train.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5753a26-a479-438d-bbc9-587ae23fba71",
   "metadata": {},
   "source": [
    "### Data Preparating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2545433-3e4b-4672-9f2b-a3daa8fb363c",
   "metadata": {},
   "source": [
    "### TrainModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b2a31-b4bb-4ccf-96af-1184dfc862d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f6f56ce-998e-40ee-9972-46874818f171",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b8432-fc45-4047-8dc7-194399f55b20",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb45a79-98f4-4d2a-b7c0-42e18e809112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
