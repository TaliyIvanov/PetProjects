{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc3c8b2-35fb-44c3-800e-ef9bc13a9231",
   "metadata": {},
   "source": [
    "# Decoding CTC output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b923207-7a92-47f3-9f8f-1448b2ba4285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "\n",
    "# Load precomputed CTC output\n",
    "with open('mystery_records.pickle', 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "\n",
    "# log probabilities of softmax layers [batch_size, T, vocab_size]\n",
    "log_probs = batch[\"log_probs\"]\n",
    "\n",
    "# Dictionary with index to character mapping\n",
    "ind2char = batch[\"ind2char\"]\n",
    "\n",
    "# Index of special EMPTY token\n",
    "EMPTY_TOK = '^'\n",
    "EMPTY_IND = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6482196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 655, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b56a8bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '^',\n",
       " 1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 27: ' '}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86f4fc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "       23, 23,  0,  5,  0,  0,  0,  0,  0,  0, 27, 14, 14, 15,  0,  0,  0,\n",
       "        0, 19, 19,  0, 20, 20,  0, 18,  0,  0, 14, 14,  0,  0,  7,  7,  0,\n",
       "        5,  0,  0,  0,  0, 19, 19,  0,  0, 20, 20,  0, 15,  0,  0,  0,  0,\n",
       "        0,  0, 27, 27, 12, 12,  0, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, 22, 22,  5,  5,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, 27, 27, 27, 25, 25, 15, 21, 21,  0, 27, 27, 11, 11, 14, 15,\n",
       "        0,  0, 23,  0,  0, 27, 27, 20,  8,  5,  0,  0,  0,  0,  0,  0, 18,\n",
       "        0,  0, 15,  0,  0,  0, 12, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "       19, 19,  0,  0,  0,  0,  0,  0,  0, 27, 27, 27,  1,  0, 14, 14,  4,\n",
       "        4,  0,  0,  0,  0,  0, 27, 27,  0, 19, 19,  0,  0, 15,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 27, 27,  4,  4,  0, 15,  0,\n",
       "        0,  0,  0,  0,  0, 27, 27,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  9,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0, 27, 27, 27,  0,  1,  0,  0,  0,  0,  0, 27, 27,  6,\n",
       "        0,  0, 15, 12,  0, 12, 12,  0,  0, 27,  3,  3,  0, 15,  0,  0, 13,\n",
       "        0,  0,  0,  0,  0, 13,  0,  9,  0,  0, 20, 20, 20,  0,  0, 13,  0,\n",
       "        5,  0, 14, 14, 20, 20,  0,  0, 27, 27, 23,  8,  8,  1,  0,  0,  0,\n",
       "       20, 20, 20, 27, 27,  0,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0, 27, 27, 20, 20,  8,  8,  9,  0, 14, 14,\n",
       "       14,  0, 11, 11, 11,  0,  9,  9, 14, 14,  7,  7,  7,  0,  0, 27, 27,\n",
       "        0, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  6,  6,  6,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, 27, 27, 25, 25, 15, 15, 21, 21,  0,\n",
       "        0,  0, 27, 27, 23, 23,  0, 15,  0,  0,  0, 12,  4,  4,  0,  5,  0,\n",
       "       14,  0,  0,  0,  0, 27, 27,  7,  0,  0,  5,  0,  0,  0, 20,  0,  0,\n",
       "       27, 27, 20,  8,  9,  0,  0,  0,  0,  0, 19, 19,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0, 27, 27,  6, 18, 18, 15,  0, 13,  0,  0,  0,  0,\n",
       "        0,  0, 27, 27,  0,  0,  1,  0,  0,  0, 14,  0,  0,  0,  0, 25, 25,\n",
       "        0,  0,  0,  0,  0, 27, 27,  0,  1,  0,  0,  0,  0,  0,  0, 20,  8,\n",
       "        8,  5, 18,  0,  0,  0,  0, 27, 27,  0,  7,  0, 21,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.argmax(-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "922cbf65-fbaf-48d5-8605-ea41c3f80590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) we nostrngesto love you know therols and so do i a foll commitment what i thinking of you wolden get this from any ather guy\n",
      "1)  never gona give you up never donelet you down never go arun around and deset you never gon a make you cri never gonna say good by\n"
     ]
    }
   ],
   "source": [
    "def ctc_decode(inds, ind2char):\n",
    "    decoder = [] # хранилище для нормальной, декодированной последовательности\n",
    "    last_char_ind = EMPTY_IND\n",
    "    for ind in inds:\n",
    "        if last_char_ind == ind:\n",
    "            continue\n",
    "        if ind != EMPTY_IND:\n",
    "            decoder.append(ind2char[ind])\n",
    "        last_char_ind = ind\n",
    "    return ''.join(decoder)\n",
    "\n",
    "for i, rec in enumerate(log_probs):\n",
    "    text = ctc_decode(rec.argmax(-1).numpy(), ind2char)\n",
    "    print(f\"{i}) {text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c4d50-e633-4e85-8842-a6b50602b70f",
   "metadata": {},
   "source": [
    "# Computing WER and CER\n",
    "Task: Implemet WER and CER metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ca11f70-ee02-4765-b542-96186781a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library for fast quick calculation of edit distance\n",
    "import editdistance\n",
    "\n",
    "# версия авторов\n",
    "def calc_wer(target_text: str, pred_text: str):\n",
    "    if len(target_text) == 0:\n",
    "        return 1\n",
    "    return editdistance.eval(target_text.split(), pred_text.split())/len(target_text.split())\n",
    "\n",
    "# моя реализация WER, до того, как я посмотрел, чтобы сделать работу над ошибками\n",
    "# разумеется это некорректно, т.к., возможно смещение слов и я просто все сделаю неправильно\n",
    "# ошибки - лучшие учителя!)\n",
    "def my_calc_wer(target_text: str, pred_text: str):\n",
    "    target_text = target_text.split()\n",
    "    pred_text = pred_text.split()\n",
    "    counter = 0\n",
    "    for i in range(len(target_text)):\n",
    "        if target_text[i] != pred_text[i]:\n",
    "            counter += 1\n",
    "    return (counter/len(target_text))*100\n",
    "    \n",
    "\n",
    "def calc_cer(target_text: str, pred_text: str):\n",
    "    if len(target_text) == 0:\n",
    "        return 1\n",
    "\n",
    "    return editdistance.eval(target_text, pred_text)/len(target_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c391511-7469-4ed8-bd26-057c4fde4717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for target, pred, expected_wer, expected_cer in [\n",
    "    (\"if you can not measure it you can not improve it\", \n",
    "     \"if you can nt measure t yo can not i\", \n",
    "     0.454, 0.25),\n",
    "    (\"if you cant describe what you are doing as a process you dont know what youre doing\", \n",
    "     \"if you cant describe what you are doing as a process you dont know what youre doing\", \n",
    "     0.0, 0.0),\n",
    "    (\"one measurement is worth a thousand expert opinions\", \n",
    "     \"one  is worth thousand opinions\", \n",
    "     0.375, 0.392)\n",
    "]:\n",
    "    wer = calc_wer(target, pred)\n",
    "    cer = calc_cer(target, pred)\n",
    "    assert np.isclose(wer, expected_wer, atol=1e-3), f\"true: {target}, pred: {pred}, expected wer {expected_wer} != your wer {wer}\"\n",
    "    assert np.isclose(cer, expected_cer, atol=1e-3), f\"true: {target}, pred: {pred}, expected cer {expected_cer} != your cer {cer}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cefd76b-66d4-4b1e-ae1d-be6b7336a160",
   "metadata": {},
   "source": [
    "Task: come up with such a pair of target-prediction texts, so the\n",
    "1) WER > 1.0\n",
    "2) CER > WER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde6b02c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11bceaaf-7b17-466b-ac17-855e4d54cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) WER > 1.0\n",
    "# your code here\n",
    "target, prediction = \"a\" , \"a a a a a \"\n",
    "assert calc_wer(target, prediction) > 1.0\n",
    "\n",
    "# 2) CER > WER\n",
    "# your code here\n",
    "target, prediction = \"a a a\", \"bbbbbb a a\"\n",
    "assert calc_wer(target, prediction) < calc_cer(target, prediction) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1fb97-4853-4190-835d-31ead094679c",
   "metadata": {},
   "source": [
    "# Beam search\n",
    "Task: implement beam-search on CTC outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8e1c37a-93be-47a1-8211-9b47d0721d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 310, 28])\n",
      "{0: '^', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: ' '}\n",
      "['he would go to her and tell her all his family complications', 'he did not say the last as a boast but merely as an assurance to the liveryman who he saw was anxious on his account', 'he started to conscious confusion only neither knowing where he was nor what he did', \"i'm here because the matter is of utmost importance and brandd is the one i must see now stand aside\", \"of course it ain't said missus bozzle\", 'mister verloc was fully responsive now', 'oh what shall we do for a home', \"line of battle was formed on the north bank of stone's river on the yankee side\", 'from fifteen to twenty minutes will be required to bake them nicely', 'whom is he going to flog now']\n"
     ]
    }
   ],
   "source": [
    "# Load precomputed CTC output\n",
    "with open('lj_batch.pickle', 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "\n",
    "# log probabilities of softmax layers [batch_size, T, vocab_size]\n",
    "log_probs = batch[\"log_probs\"]\n",
    "\n",
    "# Dictionary with index to character mapping\n",
    "ind2char = batch[\"ind2char\"]\n",
    "\n",
    "true_texts = batch[\"text\"]\n",
    "\n",
    "print(log_probs.size())\n",
    "print(ind2char)\n",
    "print(true_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceed2d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[9.9979e-01, 1.5032e-06, 2.3595e-07,  ..., 3.1434e-07,\n",
      "          1.0038e-08, 2.7595e-09],\n",
      "         [9.9998e-01, 8.6571e-08, 9.8482e-09,  ..., 4.6133e-08,\n",
      "          1.7876e-10, 7.6316e-11],\n",
      "         [1.0000e+00, 2.2588e-08, 2.7001e-09,  ..., 6.8390e-09,\n",
      "          1.1855e-11, 5.2869e-12],\n",
      "         ...,\n",
      "         [1.0000e+00, 4.8414e-08, 1.0775e-08,  ..., 4.0093e-09,\n",
      "          6.8794e-12, 5.7046e-08],\n",
      "         [9.9932e-01, 1.5367e-06, 3.9040e-07,  ..., 1.1833e-07,\n",
      "          1.5983e-10, 6.7376e-04],\n",
      "         [6.8953e-01, 4.6144e-04, 1.8930e-04,  ..., 1.8095e-04,\n",
      "          2.3677e-07, 3.0813e-01]],\n",
      "\n",
      "        [[9.9993e-01, 9.8160e-07, 4.9533e-07,  ..., 1.9043e-07,\n",
      "          1.2068e-09, 1.8334e-11],\n",
      "         [9.9999e-01, 9.7628e-08, 1.5065e-07,  ..., 7.9602e-08,\n",
      "          6.0507e-11, 3.7560e-13],\n",
      "         [1.0000e+00, 1.3857e-08, 3.5957e-08,  ..., 6.2041e-09,\n",
      "          1.8368e-12, 1.6559e-14],\n",
      "         ...,\n",
      "         [1.0000e+00, 1.0177e-07, 3.9941e-09,  ..., 3.9199e-09,\n",
      "          9.7420e-12, 4.4569e-08],\n",
      "         [9.9950e-01, 3.7950e-06, 1.3520e-07,  ..., 1.0044e-07,\n",
      "          2.0598e-10, 4.8555e-04],\n",
      "         [7.5707e-01, 2.0332e-03, 8.9497e-05,  ..., 1.2991e-04,\n",
      "          3.4057e-07, 2.3912e-01]],\n",
      "\n",
      "        [[9.9988e-01, 1.4440e-06, 1.1059e-06,  ..., 1.1724e-07,\n",
      "          2.0173e-09, 2.2795e-10],\n",
      "         [9.9999e-01, 1.0576e-07, 2.8518e-07,  ..., 1.0540e-08,\n",
      "          2.2580e-11, 2.4709e-12],\n",
      "         [1.0000e+00, 2.8421e-08, 9.8390e-08,  ..., 9.0451e-10,\n",
      "          9.0498e-13, 1.3529e-13],\n",
      "         ...,\n",
      "         [1.0000e+00, 5.3022e-08, 2.4743e-09,  ..., 9.0832e-10,\n",
      "          2.2840e-12, 4.4918e-08],\n",
      "         [9.9943e-01, 1.9161e-06, 8.8970e-08,  ..., 2.3102e-08,\n",
      "          4.8001e-11, 5.6845e-04],\n",
      "         [6.8177e-01, 7.0584e-04, 5.1683e-05,  ..., 3.2580e-05,\n",
      "          8.0595e-08, 3.1678e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[9.9982e-01, 3.6935e-06, 7.4856e-07,  ..., 3.4064e-07,\n",
      "          5.1741e-09, 6.7959e-11],\n",
      "         [9.9998e-01, 5.7009e-07, 2.4890e-07,  ..., 8.9195e-08,\n",
      "          1.9642e-10, 8.5519e-13],\n",
      "         [1.0000e+00, 7.5976e-08, 4.3204e-08,  ..., 7.7707e-09,\n",
      "          8.2751e-12, 3.5086e-14],\n",
      "         ...,\n",
      "         [1.0000e+00, 1.7674e-07, 1.0887e-08,  ..., 4.5958e-09,\n",
      "          8.4070e-12, 1.5414e-07],\n",
      "         [9.9811e-01, 7.2063e-06, 3.4000e-07,  ..., 1.5178e-07,\n",
      "          1.7826e-10, 1.8684e-03],\n",
      "         [4.4592e-01, 2.0491e-03, 1.1380e-04,  ..., 1.8002e-04,\n",
      "          1.9670e-07, 5.4944e-01]],\n",
      "\n",
      "        [[9.9990e-01, 3.4523e-06, 2.1285e-08,  ..., 4.5527e-07,\n",
      "          6.7157e-10, 8.5617e-10],\n",
      "         [1.0000e+00, 9.0772e-08, 1.1433e-09,  ..., 6.5831e-09,\n",
      "          4.0938e-12, 1.6757e-11],\n",
      "         [1.0000e+00, 3.4467e-08, 3.4612e-09,  ..., 2.2416e-09,\n",
      "          6.5133e-13, 4.1992e-12],\n",
      "         ...,\n",
      "         [1.0000e+00, 6.0434e-08, 5.2103e-09,  ..., 2.3792e-09,\n",
      "          3.2792e-12, 6.5806e-08],\n",
      "         [9.9925e-01, 1.8652e-06, 1.7305e-07,  ..., 5.8346e-08,\n",
      "          6.5796e-11, 7.4277e-04],\n",
      "         [6.4117e-01, 6.1498e-04, 8.5924e-05,  ..., 7.6937e-05,\n",
      "          9.6138e-08, 3.5688e-01]],\n",
      "\n",
      "        [[9.9996e-01, 1.0709e-06, 1.2868e-07,  ..., 1.0488e-07,\n",
      "          1.4230e-10, 3.2535e-11],\n",
      "         [1.0000e+00, 1.1244e-07, 6.6944e-08,  ..., 1.1110e-08,\n",
      "          6.9148e-12, 6.8256e-13],\n",
      "         [1.0000e+00, 1.1877e-08, 1.6501e-08,  ..., 9.4506e-10,\n",
      "          3.2301e-13, 1.8304e-14],\n",
      "         ...,\n",
      "         [1.0000e+00, 5.2290e-08, 6.4751e-09,  ..., 3.4469e-09,\n",
      "          3.7628e-12, 4.6429e-08],\n",
      "         [9.9936e-01, 2.0146e-06, 2.3178e-07,  ..., 1.1819e-07,\n",
      "          8.9045e-11, 6.3510e-04],\n",
      "         [6.3849e-01, 7.7063e-04, 1.2101e-04,  ..., 2.1654e-04,\n",
      "          1.7546e-07, 3.5869e-01]]])\n"
     ]
    }
   ],
   "source": [
    "# возьмем просто prob через экспоненты\n",
    "probs = log_probs.exp()\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ae1f264-33cb-4c4d-b959-823d07843936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Функция для расширения и слияния путей\n",
    "def expand_and_merge_path(dp, next_token_probs, ind2char):\n",
    "    new_dp = defaultdict(float)\n",
    "    for ind, next_token_prob in enumerate(next_token_probs):\n",
    "        cur_char = ind2char[ind]\n",
    "        for (prefix, last_char), v in dp.items():\n",
    "            if last_char == cur_char:\n",
    "                new_prefix = prefix  # Если последний символ тот же, не изменяем префикс\n",
    "            else:\n",
    "                if cur_char != EMPTY_TOK:\n",
    "                    new_prefix = prefix + cur_char  # Если символ пустой, добавляем его в префикс\n",
    "                else:\n",
    "                    new_prefix = prefix  # Для всех других символов, добавляем их в префикс\n",
    "            new_dp[(new_prefix, cur_char)] += v * next_token_prob  # Обновляем вероятности\n",
    "    return new_dp\n",
    "\n",
    "# Функция для усечения путей (beam search)\n",
    "def truncate_paths(dp, beam_size):\n",
    "    # Возвращаем лучшие beam_size путей\n",
    "    return dict(sorted(dp.items(), key=lambda x: -x[1])[:beam_size])\n",
    "\n",
    "# Основная функция для CTC beam search\n",
    "def ctc_beam_search(probs, beam_size, ind2char):\n",
    "    dp = {\n",
    "        ('', EMPTY_TOK): 1.0,  # Начальный путь с пустым токеном\n",
    "    }\n",
    "    for prob in probs:\n",
    "        dp = expand_and_merge_path(dp, prob, ind2char)  # Расширение путей\n",
    "        dp = truncate_paths(dp, beam_size)  # Усечение путей до лучшего beam_size\n",
    "    dp = [(prefix, proba) for (prefix, _), proba in sorted(dp.items(), key=lambda x: -x[1])]\n",
    "    return dp\n",
    "\n",
    "# Пример применения для log_probs\n",
    "bs_results = []\n",
    "for log_probs_line in log_probs:\n",
    "    bs_results.append(ctc_beam_search(log_probs_line.exp().numpy(), 100, ind2char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e6d7249-aed1-4ff3-8ce2-20978320ac7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  he would go to her and tell her all his family complications\n",
      "Argmax: he wld ge toher iand tell her all mhisan ly omblications --- (CER: 0.200)\n",
      "1) 'he wl ge to her iand tell her all hisan ly omblications' --- (CER: 0.183)\n",
      "2) 'he wl ge to her and tell her all hisan ly omblications' --- (CER: 0.167)\n",
      "3) 'he wl ge to her iand tell her all hisanly omblications' --- (CER: 0.183)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  he did not say the last as a boast but merely as an assurance to the liveryman who he saw was anxious on his account\n",
      "Argmax: he did not sad the last is a bost but mearlioves an asurance to the livery man who re saw was anxes on his account --- (CER: 0.129)\n",
      "1) 'he did not say the last is a bost but merli oves an a surance to the livery man who re saw was anxes on his account' --- (CER: 0.112)\n",
      "2) 'he did not say the last as a bost but merli oves an a surance to the livery man who re saw was anxes on his account' --- (CER: 0.103)\n",
      "3) 'he did not say the last is a bost but merli oves an a surance to the livery man who re saw was anxies on his account' --- (CER: 0.103)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  he started to conscious confusion only neither knowing where he was nor what he did\n",
      "Argmax: he started to consces confusion only neither knowing where he was nor what he did --- (CER: 0.036)\n",
      "1) 'he started to consces confusion only neither knowing where he was nor what he did' --- (CER: 0.036)\n",
      "2) 'he started to consces confusion only neither knowwing where he was nor what he did' --- (CER: 0.048)\n",
      "3) 'he started to consces confusion only neither knowing where he was nor what he did ' --- (CER: 0.048)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  i'm here because the matter is of utmost importance and brandd is the one i must see now stand aside\n",
      "Argmax: imcere because he matderacis of ut most omportanceand brand is o vammasea nhostend aside --- (CER: 0.280)\n",
      "1) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nho stend aside' --- (CER: 0.260)\n",
      "2) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nhostend aside' --- (CER: 0.270)\n",
      "3) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nhestend aside' --- (CER: 0.270)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  of course it ain't said missus bozzle\n",
      "Argmax: of coursit int said missus bozol --- (CER: 0.162)\n",
      "1) 'of cours it int said missus bozol' --- (CER: 0.135)\n",
      "2) 'of cours it int said missus bozol ' --- (CER: 0.135)\n",
      "3) 'of cours it int said missus bozal' --- (CER: 0.135)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  mister verloc was fully responsive now\n",
      "Argmax: mister volockwass fuly respons of mow --- (CER: 0.237)\n",
      "1) 'mister volockwass fuly respons of mow' --- (CER: 0.237)\n",
      "2) 'mister volockwass fuli respons of mow' --- (CER: 0.263)\n",
      "3) 'mister volockwass fuly resplons of mow' --- (CER: 0.263)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  oh what shall we do for a home\n",
      "Argmax: oh what shal we do for a whom --- (CER: 0.100)\n",
      "1) 'oh what shal we do for a whom' --- (CER: 0.100)\n",
      "2) 'ohh what shal we do for a whom' --- (CER: 0.133)\n",
      "3) 'oh what shal we do for a whom ' --- (CER: 0.100)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  line of battle was formed on the north bank of stone's river on the yankee side\n",
      "Argmax: line of battle was formed on the north bank of stones river on the yanky sidt  --- (CER: 0.063)\n",
      "1) 'wine of battle was formed on the north bank of stones river on the yanky side ' --- (CER: 0.063)\n",
      "2) 'line of battle was formed on the north bank of stones river on the yanky side ' --- (CER: 0.051)\n",
      "3) 'wine of battle was formed on the north bank of stones river on the yanky side' --- (CER: 0.051)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  from fifteen to twenty minutes will be required to bake them nicely\n",
      "Argmax: fror fifteen t teny minites will be required to bake the nicely --- (CER: 0.090)\n",
      "1) 'fror fifteengt tweny minites will be required to bake the nicely' --- (CER: 0.090)\n",
      "2) 'fror fifteen t tweny minites will be required to bake the nicely' --- (CER: 0.075)\n",
      "3) 'fror fifteengt tweny minutes will be required to bake the nicely' --- (CER: 0.075)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  whom is he going to flog now\n",
      "Argmax: whoom is agoing to flag no --- (CER: 0.214)\n",
      "1) 'whoom is agoing to flagd now' --- (CER: 0.214)\n",
      "2) 'whoom is agoing to flogd now' --- (CER: 0.179)\n",
      "3) 'whoom is agoing to flaugd now' --- (CER: 0.250)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(true_texts)):\n",
    "    beam_search_hypos = bs_results[i][:3]\n",
    "    true_text = true_texts[i]\n",
    "    argmax_text = ctc_decode(log_probs[i].numpy().argmax(-1), ind2char)\n",
    "    print(\"True: \", true_text)\n",
    "    print(f\"Argmax: {argmax_text} --- (CER: {calc_cer(true_text, argmax_text):.3f})\")\n",
    "    for ind, (hypo, score) in enumerate(beam_search_hypos):\n",
    "        print(f\"{ind+1}) '{hypo}' --- (CER: {calc_cer(true_text, hypo):.3f})\")\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c63d08",
   "metadata": {},
   "source": [
    "У меня слишком высокий показатель ошибки. видимо это связано с тем, что учитывается ^ данный символ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLAvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
