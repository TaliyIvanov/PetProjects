{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDsVMGiVgSq2"
   },
   "source": [
    "## Переобучение нейронных сетей и борьба с ним\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/girafe_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3isBRG6PgSq6"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "def args_and_kwargs(*args, **kwargs):\n",
    "    return args, kwargs\n",
    "\n",
    "def parse_pytorch_model(model_str):\n",
    "    def parse_layer(layer_str):\n",
    "        layer_name, params = layer_str.split(\"(\", 1)\n",
    "        layer_info = {\"type\": layer_name.strip()}\n",
    "        params_template = layer_str.replace(layer_name, \"args_and_kwargs\")\n",
    "        \n",
    "        param_dict = {}\n",
    "        if len(params):\n",
    "            args, kwargs = eval(params_template)\n",
    "            if len(args) or len(kwargs):\n",
    "                param_dict[\"args\"] = args\n",
    "                for name, value in kwargs.items():\n",
    "                    param_dict[name] = value\n",
    "        layer_info[\"parameters\"] = param_dict\n",
    "        return layer_info\n",
    "\n",
    "    model_dict = {}\n",
    "    lines = model_str.splitlines()\n",
    "    model_name = lines[0].strip(\"()\")\n",
    "    model_dict[\"model_name\"] = model_name\n",
    "    model_dict[\"layers\"] = []\n",
    "\n",
    "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
    "    for line in lines[1:]:\n",
    "        line = line.strip()\n",
    "        match = layer_regex.match(line)\n",
    "        if match:\n",
    "            index, layer = match.groups()\n",
    "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
    "    return model_dict\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            y_predicted = model(batch[0].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "            real_labels.append(batch[1])\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    real_labels = torch.cat(real_labels)\n",
    "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-19 15:38:07--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
      "--2025-04-19 15:38:08--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8002::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6272446 (6.0M) [application/octet-stream]\n",
      "Saving to: ‘hw_overfitting_data_dict.npy’\n",
      "\n",
      "hw_overfitting_data 100%[===================>]   5.98M  19.7MB/s    in 0.3s    \n",
      "\n",
      "2025-04-19 15:38:08 (19.7 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeA6Q5-CgSq7"
   },
   "source": [
    "### Задача №1 (уже решённая): Создание и обучение модели (Separation)\n",
    "Вы уже решали эту задачу ранее, так что сейчас просто воспроизведите своё решение. Оно понадобится вам в дальнейших шагах.\n",
    "__Ваша первая задача всё та же: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE_ID = 0  # change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nPG1KbQAgl8b"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = (\n",
    "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "aYcL28OsgSq8",
    "outputId": "93aafa07-fb56-43bd-f928-918f45fe30e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 5')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_fmnist_data = FashionMNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_fmnist_data = FashionMNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6jWRv1rgSq8"
   },
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BcyEFX-RgSq8"
   },
   "outputs": [],
   "source": [
    "# Creating model instance\n",
    "model_task_1 = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64 * 7 * 7, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAoLV4dkoy5M"
   },
   "source": [
    "Не забудьте перенести модель на выбранный `device`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Xas9SIXDoxvZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLRWysggSq9"
   },
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qMQzo1ggSq9",
    "outputId": "c00008eb-ef88-4000-ce47-e8dedd26e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].to(device)\n",
    "    y = random_batch[1].to(device)\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model_task_1(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suRmIPwIgSq9"
   },
   "source": [
    "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YJnU14bdnZa_"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model_task_1.parameters(), lr=0.005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 512.8827, Accuracy: 89.94%\n",
      "Epoch 2/30, Loss: 453.8554, Accuracy: 90.97%\n",
      "Epoch 3/30, Loss: 413.9790, Accuracy: 91.66%\n",
      "Epoch 4/30, Loss: 388.9262, Accuracy: 92.24%\n",
      "Epoch 5/30, Loss: 365.8580, Accuracy: 92.61%\n",
      "Epoch 6/30, Loss: 344.4074, Accuracy: 93.07%\n",
      "Epoch 7/30, Loss: 328.3658, Accuracy: 93.48%\n",
      "Epoch 8/30, Loss: 306.2953, Accuracy: 93.84%\n",
      "Epoch 9/30, Loss: 300.3689, Accuracy: 93.98%\n",
      "Epoch 10/30, Loss: 287.8019, Accuracy: 94.12%\n",
      "Epoch 11/30, Loss: 276.7882, Accuracy: 94.36%\n",
      "Epoch 12/30, Loss: 265.6422, Accuracy: 94.58%\n",
      "Epoch 13/30, Loss: 262.1603, Accuracy: 94.71%\n",
      "Epoch 14/30, Loss: 262.5751, Accuracy: 94.78%\n",
      "Epoch 15/30, Loss: 251.1379, Accuracy: 94.98%\n",
      "Epoch 16/30, Loss: 245.0853, Accuracy: 95.14%\n",
      "Epoch 17/30, Loss: 242.8658, Accuracy: 95.16%\n",
      "Epoch 18/30, Loss: 233.2202, Accuracy: 95.35%\n",
      "Epoch 19/30, Loss: 238.8551, Accuracy: 95.27%\n",
      "Epoch 20/30, Loss: 225.7132, Accuracy: 95.51%\n",
      "Epoch 21/30, Loss: 224.1756, Accuracy: 95.48%\n",
      "Epoch 22/30, Loss: 219.3190, Accuracy: 95.63%\n",
      "Epoch 23/30, Loss: 220.8733, Accuracy: 95.56%\n",
      "Epoch 24/30, Loss: 216.9046, Accuracy: 95.72%\n",
      "Epoch 25/30, Loss: 213.3699, Accuracy: 95.74%\n",
      "Epoch 26/30, Loss: 212.6634, Accuracy: 95.80%\n",
      "Epoch 27/30, Loss: 210.4030, Accuracy: 95.88%\n",
      "Epoch 28/30, Loss: 205.1746, Accuracy: 95.92%\n",
      "Epoch 29/30, Loss: 199.3110, Accuracy: 96.02%\n",
      "Epoch 30/30, Loss: 205.2822, Accuracy: 95.90%\n",
      "Обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "# цикл обучения\n",
    "# переводим модель в режим обучения\n",
    "EPOCHS = 30\n",
    "for epoch in range(EPOCHS):\n",
    "    model_task_1.train()\n",
    "    running_loss=0\n",
    "    correct = 0\n",
    "    total=0\n",
    "\n",
    "    for images, labels in train_data_loader:\n",
    "        # переводим все на CUDA\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # прямой проход\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_task_1(images)\n",
    "        loss_value = loss(outputs, labels)\n",
    "        # обратный проход для оптимищации весов\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss_value.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    lr_scheduler.step(running_loss)\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Обучение завершено!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zce7gt1gSq-"
   },
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usswrWYOgSq-"
   },
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Xua3TVZHgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.96307\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "l9KEKXBxgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.8986\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyhmMobgSq_"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "OAIrURCEgSq_",
    "outputId": "7c983690-a92e-4693-89fb-7c86c002921a"
   },
   "outputs": [],
   "source": [
    "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
    "assert (\n",
    "    train_acc_task_1 >= 0.905\n",
    "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_task_1.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "    ),\n",
    "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_task_1.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_task_1.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №2: Переобучение (Initiation)\n",
    "Продолжим работу с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Теперь ваша задача продемонстрировать переобучение модели на обучающей выборке. Достаточно показать, что точность классификации (не только функция потерь!) на тестовой выборке значительно отстает от обучающей.\n",
    "\n",
    "Обращаем ваше внимание, в задаче №3 вам придется починить данную модель (минимизировать эффект переобучения) с помощью механизмов регуляризации, поэтому не переусердствуйте!\n",
    "\n",
    "__Ваша вторая задача: реализовать используя пайплан обучения модели продемонстрировать переобучения модели на обучающей выборке.__\n",
    "\n",
    "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимание, вам необходимо использовать переменную `model_task_2` для хранение модели во второй задаче. \n",
    "\n",
    "Не используйте `Dropout` и `BatchNorm` в этой задаче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model instance\n",
    "model_task_2 = nn.Sequential(\n",
    "    nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64*7*7, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model_task_2.parameters(), lr=0.005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 761.5521, Accuracy: 85.15%\n",
      "Epoch 2/50, Loss: 525.4622, Accuracy: 89.62%\n",
      "Epoch 3/50, Loss: 469.9065, Accuracy: 90.56%\n",
      "Epoch 4/50, Loss: 432.9121, Accuracy: 91.31%\n",
      "Epoch 5/50, Loss: 402.4496, Accuracy: 91.86%\n",
      "Epoch 6/50, Loss: 388.3499, Accuracy: 92.10%\n",
      "Epoch 7/50, Loss: 368.9423, Accuracy: 92.57%\n",
      "Epoch 8/50, Loss: 359.0815, Accuracy: 92.72%\n",
      "Epoch 9/50, Loss: 341.2972, Accuracy: 93.19%\n",
      "Epoch 10/50, Loss: 332.9351, Accuracy: 93.18%\n",
      "Epoch 11/50, Loss: 317.9221, Accuracy: 93.59%\n",
      "Epoch 12/50, Loss: 317.3264, Accuracy: 93.64%\n",
      "Epoch 13/50, Loss: 312.3866, Accuracy: 93.77%\n",
      "Epoch 14/50, Loss: 298.4601, Accuracy: 93.88%\n",
      "Epoch 15/50, Loss: 290.5416, Accuracy: 94.09%\n",
      "Epoch 16/50, Loss: 293.2287, Accuracy: 94.04%\n",
      "Epoch 17/50, Loss: 283.8800, Accuracy: 94.27%\n",
      "Epoch 18/50, Loss: 284.0675, Accuracy: 94.26%\n",
      "Epoch 19/50, Loss: 270.8967, Accuracy: 94.44%\n",
      "Epoch 20/50, Loss: 270.5568, Accuracy: 94.47%\n",
      "Epoch 21/50, Loss: 268.8757, Accuracy: 94.59%\n",
      "Epoch 22/50, Loss: 262.9314, Accuracy: 94.67%\n",
      "Epoch 23/50, Loss: 264.2468, Accuracy: 94.65%\n",
      "Epoch 24/50, Loss: 255.1644, Accuracy: 94.80%\n",
      "Epoch 25/50, Loss: 262.3392, Accuracy: 94.79%\n",
      "Epoch 26/50, Loss: 258.5651, Accuracy: 94.71%\n",
      "Epoch 27/50, Loss: 251.3159, Accuracy: 94.99%\n",
      "Epoch 28/50, Loss: 251.5336, Accuracy: 94.95%\n",
      "Epoch 29/50, Loss: 253.8371, Accuracy: 94.87%\n",
      "Epoch 30/50, Loss: 245.9164, Accuracy: 95.04%\n",
      "Epoch 31/50, Loss: 247.8698, Accuracy: 95.02%\n",
      "Epoch 32/50, Loss: 244.5941, Accuracy: 95.01%\n",
      "Epoch 33/50, Loss: 241.6010, Accuracy: 95.12%\n",
      "Epoch 34/50, Loss: 241.3408, Accuracy: 95.11%\n",
      "Epoch 35/50, Loss: 241.9876, Accuracy: 95.13%\n",
      "Epoch 36/50, Loss: 234.3764, Accuracy: 95.29%\n",
      "Epoch 37/50, Loss: 239.8963, Accuracy: 95.19%\n",
      "Epoch 38/50, Loss: 234.6936, Accuracy: 95.31%\n",
      "Epoch 39/50, Loss: 229.8669, Accuracy: 95.33%\n",
      "Epoch 40/50, Loss: 236.6223, Accuracy: 95.23%\n",
      "Epoch 41/50, Loss: 231.5127, Accuracy: 95.30%\n",
      "Epoch 42/50, Loss: 228.3026, Accuracy: 95.38%\n",
      "Epoch 43/50, Loss: 227.4550, Accuracy: 95.44%\n",
      "Epoch 44/50, Loss: 226.0199, Accuracy: 95.45%\n",
      "Epoch 45/50, Loss: 225.2849, Accuracy: 95.56%\n",
      "Epoch 46/50, Loss: 228.0352, Accuracy: 95.42%\n",
      "Epoch 47/50, Loss: 228.1494, Accuracy: 95.42%\n",
      "Epoch 48/50, Loss: 217.6245, Accuracy: 95.59%\n",
      "Epoch 49/50, Loss: 227.0626, Accuracy: 95.37%\n",
      "Epoch 50/50, Loss: 226.1273, Accuracy: 95.57%\n",
      "Обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "# цикл обучения\n",
    "# переводим модель в режим обучения\n",
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    model_task_2.train()\n",
    "    running_loss=0\n",
    "    correct = 0\n",
    "    total=0\n",
    "\n",
    "    for images, labels in train_data_loader:\n",
    "        # переводим все на CUDA\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # прямой проход\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_task_2(images)\n",
    "        loss_value = loss(outputs, labels)\n",
    "        # обратный проход для оптимищации весов\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss_value.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    lr_scheduler.step(running_loss)\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Обучение завершено!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка архитектуры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "layers_task_2 = []\n",
    "for element in parse_pytorch_model(str(model_task_2)).get(\"layers\", []):\n",
    "    layer_name = element[\"layer\"][\"type\"]\n",
    "    assert \"dropout\" not in layer_name.lower(), \"Do not use Dropout in Task 2!\"\n",
    "    assert \"batchnorm\" not in layer_name.lower(), \"Do not use BatchNorm in Task 2!\"\n",
    "    layers_task_2.append(layer_name)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.96332\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_2 = get_accuracy(model_task_2, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_2:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9022\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_2 = get_accuracy(model_task_2, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_2:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что переобучение присутствует:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc_task_2 >= test_acc_task_2, \"Train accuracy must be higher than task accuracy\"\n",
    "assert train_acc_task_2 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
    "assert (\n",
    "    train_acc_task_2 - test_acc_task_2 >= 0.04\n",
    "), \"Test accuracy should be at least 0.04 lower that train.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_2`.\n",
    "\n",
    "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задачи №1. Если их там нет, загрузите их из сохраненного файла в переменную перед запуском следующей ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_tasks_1_and_2.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict.update(\n",
    "    {\n",
    "        \"train_predictions_task_2\": get_predictions(\n",
    "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "        ),\n",
    "        \"test_predictions_task_2\": get_predictions(\n",
    "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "        ),\n",
    "        \"model_task_2\": parse_pytorch_model(str(model_task_2)),\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(\"submission_dict_tasks_1_and_2.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_tasks_1_and_2.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №3: Исправление модели (Return) \n",
    "Все так же работаем с [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Наконец, ваша задача исправить ~~ошибки прошлого~~ переобучение модели, построенной в задаче 2. Достаточно добиться расхождения между точностью классификации на обучающей и тестовой выборках не превышающего 0.015 (т.е. полутора процентов).\n",
    "\n",
    "Обращаем ваше внимание, архитектура модели в задаче №3 не должна существенно отличаться от задачи №2! Вы можете использовать Batchnorm, Dropout, уменьшить размерность промежуточных представлений, обратиться к аугментации данных, но вы не можете использовать меньшее количество слоёв.\n",
    "\n",
    "__Ваша третья и финальная задача: исправить модель и/или процесс обучения, дабы справиться с переобучением.__\n",
    "\n",
    "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимание, вам необходимо использовать переменную `model_task_3` для хранение модели во второй задаче. \n",
    "\n",
    "Также код ниже будет обращаться к переменной `layers_task_2`, инициализируйте её, если она не определена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert (\n",
    "    layers_task_2 is not None\n",
    "), \"Initializa layers_task_2 vairable which contains list of layers in task 2 model\"\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task_3 = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64*7*7, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Dropout(p=0.3, inplace=False)\n",
       "  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (5): ReLU()\n",
       "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): Dropout(p=0.3, inplace=False)\n",
       "  (8): Flatten(start_dim=1, end_dim=-1)\n",
       "  (9): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (10): ReLU()\n",
       "  (11): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_task_3.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1214.0284, Accuracy: 75.51%\n",
      "Epoch 2/20, Loss: 968.4309, Accuracy: 80.55%\n",
      "Epoch 3/20, Loss: 883.9432, Accuracy: 82.28%\n",
      "Epoch 4/20, Loss: 850.2809, Accuracy: 82.84%\n",
      "Epoch 5/20, Loss: 792.2862, Accuracy: 84.18%\n",
      "Epoch 6/20, Loss: 746.3061, Accuracy: 85.01%\n",
      "Epoch 7/20, Loss: 725.5436, Accuracy: 85.47%\n",
      "Epoch 8/20, Loss: 720.7363, Accuracy: 85.52%\n",
      "Epoch 9/20, Loss: 710.1709, Accuracy: 85.86%\n",
      "Epoch 10/20, Loss: 704.6304, Accuracy: 85.96%\n",
      "Epoch 11/20, Loss: 691.9046, Accuracy: 86.31%\n",
      "Epoch 12/20, Loss: 682.7729, Accuracy: 86.26%\n",
      "Epoch 13/20, Loss: 683.2714, Accuracy: 86.38%\n",
      "Epoch 14/20, Loss: 676.0814, Accuracy: 86.63%\n",
      "Epoch 15/20, Loss: 666.9897, Accuracy: 86.75%\n",
      "Epoch 16/20, Loss: 659.4352, Accuracy: 86.79%\n",
      "Epoch 17/20, Loss: 648.4765, Accuracy: 87.06%\n",
      "Epoch 18/20, Loss: 644.6688, Accuracy: 87.18%\n",
      "Epoch 19/20, Loss: 647.4360, Accuracy: 87.09%\n",
      "Epoch 20/20, Loss: 630.7134, Accuracy: 87.61%\n",
      "Обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model_task_3.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_data_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_task_3(images)\n",
    "        loss_value = loss(outputs, labels)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss_value.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    lr_scheduler.step(running_loss)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Обучение завершено!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка архитектуры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "layers_task_3 = []\n",
    "for element in parse_pytorch_model(str(model_task_3)).get(\"layers\", []):\n",
    "    layer_name = element[\"layer\"][\"type\"]\n",
    "    layers_task_3.append(layer_name)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "for model_3_layer in layers_task_3:\n",
    "    model_2_layer = layers_task_2[idx]\n",
    "    if \"dropout\" not in model_3_layer.lower() and \"batchnorm\" not in model_3_layer.lower():\n",
    "        assert (\n",
    "            model_3_layer == model_2_layer\n",
    "        ), \"Models in tasks 2 and 3 must share the architecture except for Dropout and BatchNorm!\"\n",
    "        idx += 1\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.90485\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_3 = get_accuracy(model_task_3, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_3:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.896\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_3 = get_accuracy(model_task_3, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_3:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что переобучение присутствует:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc_task_3 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
    "assert train_acc_task_3 >= 0.865, \"Test accuracy must be higher than 0.865\"\n",
    "assert (\n",
    "    train_acc_task_3 - test_acc_task_3 <= 0.015\n",
    "), \"Test accuracy should not be lower that train more than by 0.015\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_3`.\n",
    "\n",
    "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задач №1 и №2. Если их там нет, загрузите их из сохраненных файлов перед запуском следующей ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_final.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict.update(\n",
    "    {\n",
    "        \"train_predictions_task_3\": get_predictions(\n",
    "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "        ),\n",
    "        \"test_predictions_task_3\": get_predictions(\n",
    "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "        ),\n",
    "        \"model_task_3\": parse_pytorch_model(str(model_task_3)),\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(\"submission_dict_final.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_final.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xai8JL3tgSq_"
   },
   "source": [
    "### Сдача задания\n",
    "Сдайте сгенерированные файлы в соответствующие задачи в соревновании, а именно:\n",
    "* `submission_dict_tasks_1_and_2.json` в задачу Initiation\n",
    "* `submission_dict_final.json` в задачу Return.\n",
    "\n",
    "\n",
    "`submission_dict_task_1.json` сдавать не нужно, он уже был сдан ранее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtWnYAN_gSrA"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yandexenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
