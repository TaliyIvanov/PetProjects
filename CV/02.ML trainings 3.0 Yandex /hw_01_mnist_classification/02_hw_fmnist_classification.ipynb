{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDsVMGiVgSq2"
   },
   "source": [
    "## Классификация FashionMNIST\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3isBRG6PgSq6"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            y_predicted = model(batch[0].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "            real_labels.append(batch[1])\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    real_labels = torch.cat(real_labels)\n",
    "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-10 16:41:02--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
      "--2025-04-10 16:41:02--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8003::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6272446 (6.0M) [application/octet-stream]\n",
      "Saving to: ‘hw_overfitting_data_dict.npy’\n",
      "\n",
      "hw_overfitting_data 100%[===================>]   5.98M  19.6MB/s    in 0.3s    \n",
      "\n",
      "2025-04-10 16:41:03 (19.6 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeA6Q5-CgSq7"
   },
   "source": [
    "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE_ID = 0  # change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nPG1KbQAgl8b"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = (\n",
    "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "aYcL28OsgSq8",
    "outputId": "93aafa07-fb56-43bd-f928-918f45fe30e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 7')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_fmnist_data = FashionMNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_fmnist_data = FashionMNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6jWRv1rgSq8"
   },
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcyEFX-RgSq8"
   },
   "outputs": [],
   "source": [
    "# модель на линейных слоях по итогу не смогла выдавить больше 0.9 на трейне \n",
    "# и не смогла пройти финальные тесты, хотя я добавлял для нее шейдулер\n",
    "# Creating model instance\n",
    "model_task_1 = nn.Sequential(\n",
    "    nn.Flatten(), # Добавление слоя для преобразования входа в одномерный массив\n",
    "    nn.Linear(1*28*28, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task_1 = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64 * 7 * 7, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAoLV4dkoy5M"
   },
   "source": [
    "Не забудьте перенести модель на выбранный `device`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "Xas9SIXDoxvZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLRWysggSq9"
   },
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qMQzo1ggSq9",
    "outputId": "c00008eb-ef88-4000-ce47-e8dedd26e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].to(device)\n",
    "    y = random_batch[1].to(device)\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model_task_1(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suRmIPwIgSq9"
   },
   "source": [
    "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "YJnU14bdnZa_"
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=0.005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 1001.4825, Accuracy: 80.30%\n",
      "Epoch 2/30, Loss: 765.4347, Accuracy: 85.27%\n",
      "Epoch 3/30, Loss: 701.6471, Accuracy: 86.44%\n",
      "Epoch 4/30, Loss: 662.1183, Accuracy: 87.15%\n",
      "Epoch 5/30, Loss: 634.6283, Accuracy: 87.71%\n",
      "Epoch 6/30, Loss: 625.9294, Accuracy: 87.69%\n",
      "Epoch 7/30, Loss: 606.7406, Accuracy: 88.06%\n",
      "Epoch 8/30, Loss: 592.8846, Accuracy: 88.39%\n",
      "Epoch 9/30, Loss: 580.1114, Accuracy: 88.92%\n",
      "Epoch 10/30, Loss: 572.2627, Accuracy: 88.86%\n",
      "Epoch 11/30, Loss: 568.2124, Accuracy: 89.10%\n",
      "Epoch 12/30, Loss: 549.4195, Accuracy: 89.33%\n",
      "Epoch 13/30, Loss: 548.1665, Accuracy: 89.42%\n",
      "Epoch 14/30, Loss: 540.8428, Accuracy: 89.54%\n",
      "Epoch 15/30, Loss: 531.9617, Accuracy: 89.66%\n",
      "Epoch 16/30, Loss: 532.5881, Accuracy: 89.64%\n",
      "Epoch 17/30, Loss: 531.2747, Accuracy: 89.71%\n",
      "Epoch 18/30, Loss: 515.6522, Accuracy: 90.12%\n",
      "Epoch 19/30, Loss: 523.1399, Accuracy: 90.01%\n",
      "Epoch 20/30, Loss: 523.4250, Accuracy: 90.05%\n",
      "Epoch 21/30, Loss: 496.9844, Accuracy: 90.38%\n",
      "Epoch 22/30, Loss: 495.3501, Accuracy: 90.34%\n",
      "Epoch 23/30, Loss: 499.9785, Accuracy: 90.37%\n",
      "Epoch 24/30, Loss: 495.2572, Accuracy: 90.47%\n",
      "Epoch 25/30, Loss: 478.1785, Accuracy: 90.75%\n",
      "Epoch 26/30, Loss: 491.1525, Accuracy: 90.70%\n",
      "Epoch 27/30, Loss: 479.4666, Accuracy: 90.94%\n",
      "Epoch 28/30, Loss: 471.8737, Accuracy: 90.90%\n",
      "Epoch 29/30, Loss: 467.0860, Accuracy: 90.86%\n",
      "Epoch 30/30, Loss: 496.5121, Accuracy: 90.60%\n",
      "Обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "# обучение линейной модельки\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model_task_1.train()\n",
    "    running_loss=0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_data_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_task_1(images)\n",
    "        loss_value = loss(outputs, labels)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss_value.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    lr_scheduler.step(running_loss)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Обучение завершено!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zce7gt1gSq-"
   },
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usswrWYOgSq-"
   },
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 747.3643, Accuracy: 85.20%\n",
      "Epoch 2/10, Loss: 524.9905, Accuracy: 89.57%\n",
      "Epoch 3/10, Loss: 464.5081, Accuracy: 90.77%\n",
      "Epoch 4/10, Loss: 423.4203, Accuracy: 91.59%\n",
      "Epoch 5/10, Loss: 396.2626, Accuracy: 92.13%\n",
      "Epoch 6/10, Loss: 368.4992, Accuracy: 92.68%\n",
      "Epoch 7/10, Loss: 345.7150, Accuracy: 93.02%\n",
      "Epoch 8/10, Loss: 328.0670, Accuracy: 93.42%\n",
      "Epoch 9/10, Loss: 309.9520, Accuracy: 93.80%\n",
      "Epoch 10/10, Loss: 297.9039, Accuracy: 94.03%\n",
      "Обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "# обучение модели со слоями пулинга)\n",
    "# обучение линейной модельки\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model_task_1.train()\n",
    "    running_loss=0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_data_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_task_1(images)\n",
    "        loss_value = loss(outputs, labels)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss_value.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    lr_scheduler.step(running_loss)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Обучение завершено!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "Xua3TVZHgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.94025\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "l9KEKXBxgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.8984\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyhmMobgSq_"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "OAIrURCEgSq_",
    "outputId": "7c983690-a92e-4693-89fb-7c86c002921a"
   },
   "outputs": [],
   "source": [
    "assert test_acc_task_1 >= 0.885, \"Test accuracy is below 0.885 threshold\"\n",
    "assert (\n",
    "    train_acc_task_1 >= 0.905\n",
    "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_fmnist_task_1.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_fmnist_data_dict.npy\"\n",
    "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "    ),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
    "    \n",
    "* `submission_dict_fmnist_task_1.json` в задачу Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtWnYAN_gSrA"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yandexenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
