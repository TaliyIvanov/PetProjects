# Сегментация зданий на спутниковых снимках с помощью CNN и MLOps

![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange.svg)
![Docker](https://img.shields.io/badge/Docker-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.95%2B-green.svg)
![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)

Данный проект представляет собой комплексное решение задачи бинарной семантической сегментации для обнаружения зданий на спутниковых снимках. Проект охватывает полный цикл MLOps: от подготовки данных и обучения модели до развертывания в виде API с системой мониторинга.

## Оглавление

- [Обзор проекта](#-обзор-проекта)
- [Ключевые возможности](#-ключевые-возможности)
- [Технологический стек](#️-технологический-стек)
- [Структура проекта](#-структура-проекта)
- [Начало работы](#-начало-работы)
  - [Предварительные требования](#предварительные-требования)
  - [Установка и запуск](#установка-и-запуск)
- [Использование](#️-использование)
  - [Обучение модели](#обучение-модели)
  - [Предсказание на изображении](#предсказание-на-изображении)
  - [Использование API](#использование-api)
- [Мониторинг и MLOps](#-мониторинг-и-mlops)
- [Результаты](#-результаты)
- [Качество кода](#-качество-кода)
- [Дальнейшие шаги](#-дальнейшие-шаги)
- [Полезные ссылки](#-полезные-ссылки)

## Обзор проекта

Основная задача — разработка и обучение сверточной нейронной сети (CNN) для точного предсказания масок зданий на основе спутниковых изображений и возврат бинарной маски.

Процесс реализации включал в себя следующие этапы:
1.  **Подготовка данных**: Исходные большие изображения (4418×4573 пикселей) были нарезаны на более мелкие фрагменты (патчи) с перекрытием для создания обучающего датасета.
2.  **Аугментация**: Для увеличения разнообразия данных и повышения устойчивости модели применялись различные техники аугментации.
3.  **Моделирование**: Были реализованы и протестированы различные архитектуры, такие как U-Net и LinkNet.
4.  **Обучение и валидация**: Модель обучалась с использованием современных практик, включая гибкую конфигурацию экспериментов и логирование метрик.
5.  **Развертывание**: Обученная модель упакована в сервис с REST API на базе FastAPI.
6.  **Контейнеризация**: Весь проект, включая сервис и систему мониторинга, полностью контейнеризирован с помощью Docker и Docker Compose.
7.  **Мониторинг**: Проект развернут на локально сервере, сбор метрик осуществляется с помощью Prometheus, а визуализация с помощью Grafana.

## Ключевые возможности

- **Подготовка данных**: Скрипты для нарезки больших изображений и создания датасета.
- **Гибкая конфигурация**: Использование **Hydra** для управления всеми параметрами проекта (данные, модель, обучение, аугментации).
- **Эксперименты и логирование**: Интеграция с **CometML** и **W&B** для отслеживания экспериментов.
- **REST API для инференса**: Сервис на **FastAPI**, который принимает изображение и возвращает бинарную маску зданий.
- **Полная контейнеризация**: Простое развертывание всего стека с помощью **Docker Compose**.
- **Мониторинг**: Интеграция с **Prometheus** для сбора метрик и **Grafana** для их визуализации.
- **Качество кода**: Использование **Ruff** для линтинга и форматирования кода.

## Технологический стек

- **Основной язык**: Python 3.10
- **Deep Learning**: PyTorch, Segmentation Models Pytorch
- **Конфигурация**: Hydra
- **API**: FastAPI, Uvicorn
- **Контейнеризация**: Docker, Docker Compose
- **Мониторинг**: Prometheus, Grafana
- **Отслеживание экспериментов**: CometML, Weights & Biases (W&B)
- **Качество кода**: Ruff
- **CI/CD & DevOps**: Git

## Структура проекта

Проект имеет модульную структуру, управляемую через Hydra, что позволяет легко заменять и настраивать компоненты.

```
segmentation_project/
├── configs/                  # Конфигурационные файлы Hydra
│   ├── config.yaml           # Основная конфигурация
│   ├── data/dataset.yaml     # Конфигурация данных
│   ├── logger/               # Конфигурация логгеров (wandb, cometml)
│   ├── model/                # Конфигурация моделей (unet, linknet)
│   ├── train/train.yaml      # Конфигурация обучения
│   └── transforms/           # Конфигурация аугментаций
├── src/                      # Исходный код
│   ├── datasets/             # Классы датасетов
│   ├── logger/               # Модули для логирования
│   ├── loss/                 # Функции потерь
│   ├── metrics/              # Метрики
│   ├── models/               # Архитектуры моделей
│   ├── transforms/           # Трансформации данных
│   ├── utils/                # Вспомогательные функции
│   ├── trainer.py            # Логика обучения и валидации
│   └── predict.py            # Логика для инференса
├── data/                     # Данные проекта
│   ├── dataset/              # Нарезанные изображения и маски
│   └── datasources/          # Исходные спутниковые снимки
├── outputs/                  # Результаты запусков (логи, модели)
├── scripts/                  # Скрипты для запуска
│   ├── train.py              # Точка входа для обучения
│   ├── pred_image.py         # Скрипт для инференса (TBD)
│   └── api.py                # Запуск FastAPI-сервиса
├── requirements.txt          # Зависимости
├── dockerfile                # Инструкции для сборки Docker-образа
├── docker-compose.yaml       # Конфигурация для запуска сервисов
├── founded_problems.yml      # Ошибки в коде, для дальнейшего фикса и исследования
├── prometheus.yml            # Конфиги для сбора метрик работы сервиса
├── pyproject.toml            # Конфиги для поддержки кода
└── README.md                 # Описание проекта
```

## Начало работы

### Предварительные требования

- [Docker](https://www.docker.com/get-started)
- [Docker Compose](https://docs.docker.com/compose/install/)
- Git

### Установка и запуск

1.  **Клонируйте репозиторий:**
    ```bash
    git clone <your-repo-url>
    cd segmentation_project
    ```

2.  **Настройте переменные окружения (опционально):**
    Если вы планируете использовать CometML или W&B, создайте файл `.env` в корне проекта и добавьте свои API ключи:
    ```env
    # .env
    COMET_API_KEY="your_comet_api_key"
    WANDB_API_KEY="your_wandb_api_key"
    ```
    Эти переменные будут автоматически подхвачены `docker-compose.yaml`.

3.  **Сборка и запуск контейнеров:**
    Для первого запуска или после изменения `Dockerfile` или `requirements.txt` используйте команду:
    ```bash
    docker compose up --build
    ```
    Для последующих запусков, когда менялся только Python-код, достаточно:
    ```bash
    docker compose up
    ```

4.  **Проверка статуса:**
    Чтобы убедиться, что API-сервис успешно запущен, проверьте логи:
    ```bash
    docker compose logs segmentation_service
    ```

5.  **Остановка сервисов:**
    Для остановки и удаления контейнеров выполните:
    ```bash
    docker compose down
    ```

## Использование

### Обучение модели

Обучение запускается через `scripts/train.py` и полностью конфигурируется через Hydra. Вы можете изменять параметры через командную строку.

**Примеры запуска обучения:**

```bash
# Запуск с конфигурацией по умолчанию (определенной в configs/config.yaml)
python scripts/train.py

# Запуск обучения с моделью U-Net и логгером W&B
python scripts/train.py model=unet logger=wandb

# Изменение конкретного параметра, например, скорости обучения
python scripts/train.py train.optimizer.lr=0.0005
```

### Предсказание на изображении

Для получения маски для одного изображения можно использовать скрипт `scripts/pred_image.py` (в разработке).

### Использование API

После запуска контейнеров API будет доступно по адресу `http://localhost:8000`.

- **Интерактивная документация (Swagger):** [http://localhost:8000/docs](http://localhost:8000/docs)
- **Альтернативная документация (ReDoc):** [http://localhost:8000/redoc](http://localhost:8000/redoc)

Основной эндпоинт для предсказаний — `/predict`. Он принимает изображение и возвращает JSON с предсказанной маской.

## Мониторинг и MLOps

Проект включает в себя стек для мониторинга производительности и состояния сервиса:

- **Prometheus**: Собирает метрики (например, время ответа API, использование ресурсов).
  - **URL**: [http://localhost:9090](http://localhost:9090)
- **Grafana**: Визуализирует метрики, собранные Prometheus, в виде дашбордов.
  - **URL**: [http://localhost:3000](http://localhost:3000) (логин/пароль по умолчанию: `admin`/`admin`)

## Результаты

Последние результаты, полученные на тестовой выборке, показывают хорошую производительность модели.

| Метрика | Значение на валидации | Значение на тесте |
| :------ | :-------------------- | :---------------- |
| **Loss**  | 0.0687                | 0.0759            |
| **IoU**   | 0.7983                | 0.7674            |

*(Результаты от 20/07/2025)*

## Качество кода

Для поддержания чистоты и консистентности кода используется **Ruff**.

- **Проверка кода на ошибки и стиль:**
  ```bash
  ruff check .
  ```
- **Автоматическое исправление большинства проблем:**
  ```bash
  ruff check . --fix
  ```
- **Форматирование кода:**
  ```bash
  ruff format .
  ```

## Дальнейшие шаги

- [ ] Настроить **Airflow** для оркестрации пайплайнов (например, периодическое переобучение модели/моделей).
- [ ] Создать CI/CD пайплайн на **GitHub Actions** для автоматической сборки и тестирования.
- [ ] Расширить API дополнительными эндпоинтами (например, для пакетной обработки).
- [ ] Добавить больше архитектур моделей и вариантов аугментаций в конфигурацию Hydra.
- [ ] Расшрить логирование до более "зрелого". Чтобы было больше метрик, информации и т.д., а не только база
- [ ] В api.py сделать привязку трансформаций к конфигу val_transforms
- [ ] в api.py проработать гибкость задания путей до весов и архитектуры модели
- [ ] Проработать в api.py возможность загрузки пользователем не изображений, а чего то иного (ошибочные зугрузки)
- [ ] Расширить кол-во метрик и сделать более продвинутый мониторинг

## Полезные ссылки

- [Object-Based Augmentation for Building Semantic Segmentation: Ventura and Santa Rosa Case Study](https://openaccess.thecvf.com/content/ICCV2021W/ILDAV/papers/Illarionova_Object-Based_Augmentation_for_Building_Semantic_Segmentation_Ventura_and_Santa_Rosa_ICCVW_2021_paper.pdf) - Статья, которая послужила источником вдохновения.