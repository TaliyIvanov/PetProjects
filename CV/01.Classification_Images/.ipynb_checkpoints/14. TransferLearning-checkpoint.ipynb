{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd3fe850-4955-4e78-aa86-559f9c6646c1",
   "metadata": {},
   "source": [
    "### Немного теории"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe09a5-802b-4f7b-a5aa-6b5047acabba",
   "metadata": {},
   "source": [
    "**Transfer Learning (Перенос Обучения): Основные моменты**\n",
    "\n",
    "**Определение:**\n",
    "Transfer Learning - это техника машинного обучения, при которой модель, обученная на одной задаче (исходной задаче), используется в качестве отправной точки для обучения на другой, связанной задаче (целевой задаче). Цель - ускорить обучение и повысить производительность на целевой задаче за счет использования знаний, полученных на исходной задаче.\n",
    "\n",
    "**Ключевые понятия:**\n",
    "\n",
    "*   **Исходная задача (Source Task):** Задача, на которой предварительно обучается модель. Обычно это большая задача с большим объемом размеченных данных.\n",
    "*   **Целевая задача (Target Task):** Задача, для которой мы хотим обучить модель, используя знания, полученные на исходной задаче. Часто это задача с меньшим объемом данных.\n",
    "*   **Предварительно обученная модель (Pre-trained Model):** Модель, которая была обучена на исходной задаче и готова к переносу.\n",
    "*   **Перенос весов (Weight Transfer):** Перенос весов (параметров) из предварительно обученной модели в модель для целевой задачи.\n",
    "\n",
    "**Зачем нужен Transfer Learning?**\n",
    "\n",
    "*   **Экономия времени и ресурсов:** Обучение модели с нуля может быть очень затратным по времени и ресурсам. Transfer Learning позволяет использовать уже существующие знания, ускоряя процесс.\n",
    "*   **Улучшение производительности:** При недостатке данных для целевой задачи, Transfer Learning может значительно повысить производительность модели, так как модель уже обладает хорошим набором признаков, полученных на большом наборе исходных данных.\n",
    "*   **Обучение на сложных задачах:**  Transfer Learning может помочь обучить модель на сложных задачах, где обучение с нуля было бы затруднительно.\n",
    "\n",
    "**Алгоритм Transfer Learning (Общий подход):**\n",
    "\n",
    "1.  **Выбор предварительно обученной модели:**\n",
    "    *   Выбираем предварительно обученную модель, обученную на исходной задаче, которая имеет схожую природу с целевой задачей.\n",
    "    *   Например, если целевая задача связана с обработкой изображений, выбирается модель, обученная на большом наборе изображений, таком как ImageNet.\n",
    "2.  **Удаление или замена последнего слоя:**\n",
    "    *   Удаляем последний слой (классификационный слой) предварительно обученной модели.\n",
    "    *   Этот слой специфичен для исходной задачи и не подходит для целевой.\n",
    "    *   Заменяем его новым слоем (или слоями), подходящим для целевой задачи. Количество выходных нейронов соответствует числу классов в целевой задаче.\n",
    "3.  **Перенос весов (Weight Transfer):**\n",
    "    *   Замораживаем большую часть слоев предварительно обученной модели.\n",
    "    *   Это означает, что веса в этих слоях не будут меняться в процессе обучения.\n",
    "    *   Оставляем веса в последнем добавленном слое \"размороженными\".\n",
    "    *   Иногда \"размораживают\" часть последних слоев предварительно обученной модели.\n",
    "4.  **Обучение модели на целевой задаче:**\n",
    "    *   Обучаем модель (с добавленным слоем) на размеченных данных для целевой задачи.\n",
    "    *   Обучается только добавленный слой или размороженные слои, используя небольшой learning rate.\n",
    "    *   Если нужно, после нескольких эпох, можно постепенно разморозить больше слоев.\n",
    "5.  **Тонкая настройка (Fine-tuning):**\n",
    "    *   На этом этапе, если это необходимо, размораживаются все слои (или большая их часть) и обучается вся модель с очень маленьким learning rate.\n",
    "    *   Это позволяет модели более точно адаптироваться к целевой задаче.\n",
    "\n",
    "**Виды Transfer Learning:**\n",
    "\n",
    "*   **Feature Extraction:** Замораживаются все слои базовой модели и используется выход одного из последних слоев как признаки для обучения классификатора.\n",
    "*   **Fine-tuning:** Как описано выше, размораживаем часть слоев и обучаем всю модель на целевых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a04e258-a0d0-49d8-9ce0-163071e6b348",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af54b433-3335-49d5-b2a1-190f5a182727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# для загрузки данных\n",
    "import requests\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff6845c1-bd98-42f8-9584-2312e0232f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc51a0-8829-441a-810e-e31e23d3efb3",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95983527-b50c-4191-8d8f-8fc3e00a6e85",
   "metadata": {},
   "source": [
    "Код для загрузки и распаковки зип архивов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46823259-281f-46a6-97a3-baa39c30fb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the data...\n",
      "Download complete.\n",
      "Unzipping...\n",
      "Unzip complete.\n"
     ]
    }
   ],
   "source": [
    "DATA_URL = 'https://download.pytorch.org/tutorial/hymenoptera_data.zip'\n",
    "DATA_PATH = os.path.join('.', 'data')\n",
    "FILE_NAME = os.path.join(DATA_PATH, 'hymenoptera_data.zip')\n",
    "\n",
    "if not os.path.isfile(FILE_NAME):\n",
    "    print('Downloading the data...')\n",
    "    os.makedirs(DATA_PATH, exist_ok=True)\n",
    "    try:\n",
    "        response = requests.get(DATA_URL, timeout=10)\n",
    "        response.raise_for_status()  # Проверка на HTTP-ошибки\n",
    "        with open(FILE_NAME, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print('Download complete.')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print('Download failed:', e)\n",
    "        exit(1)  # Прерываем выполнение при ошибке\n",
    "else:\n",
    "    print(FILE_NAME, 'already exists, skipping download...')\n",
    "\n",
    "# Разархивируем файл\n",
    "try:\n",
    "    with zipfile.ZipFile(FILE_NAME, 'r') as zip_ref:\n",
    "        print('Unzipping...')\n",
    "        zip_ref.extractall(DATA_PATH)\n",
    "    print('Unzip complete.')\n",
    "except zipfile.BadZipFile:\n",
    "    print('Error: File is not a valid ZIP archive.')\n",
    "    exit(1)\n",
    "\n",
    "DATA_PATH = os.path.join(DATA_PATH, 'hymenoptera_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11fc1647-4d51-461b-b284-529310cc40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код выше по сути заменяют две данные строки:\n",
    "# !wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
    "# !unzip hymenoptera_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a1fc29-032b-449d-a5d3-5885cd06a8c3",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35acfff3-3857-4202-840b-cca12f1d42b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transforms_val = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed6035fb-5a91-4973-b39b-87fc1e6303bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder('data/hymenoptera_data/train', transform=transforms_train)\n",
    "val_data = datasets.ImageFolder('data/hymenoptera_data/val', transform=transforms_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68ddd4f6-f66c-4695-b899-0257a55ddcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 244\n",
      "    Root location: data/hymenoptera_data/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=256, interpolation=bilinear, max_size=None, antialias=True)\n",
      "               RandomCrop(size=(224, 224), padding=None)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 153\n",
      "    Root location: data/hymenoptera_data/val\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=256, interpolation=bilinear, max_size=None, antialias=True)\n",
      "               CenterCrop(size=(224, 224))\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "561cd6bf-32cc-4123-a19a-f7f10ee6d485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ants', 'bees']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_names = train_data.classes\n",
    "classes_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5ac9377-3159-46d1-8d65-c199692ef62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682dbc0d-1664-4a94-b068-c31324a30b1e",
   "metadata": {},
   "source": [
    "### Обучение с нуля без TransferLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a6a3d-7b2a-4296-a04e-34614a68b42f",
   "metadata": {},
   "source": [
    "#### Вариант 1\n",
    "1. Модель не обучена.\n",
    "2. Меняем только последний слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85ce56de-601b-4b67-8821-280591e4b4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализируем модельку\n",
    "model = models.vgg11()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e69f9ce-b3a2-4d6b-a4db-4830ff1f474d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смотрим на классификатор, в котором мы будем менять только последний слой\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6b40a17-a686-4e0b-b55b-67de95ad3e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заменим последний слой на наш, линейный\n",
    "model.classifier[6] = nn.Linear(4096,2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78af1f3f-adee-4907-a8af-650e9e4f28e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переводим модель на cuda\n",
    "model = model.to(device)\n",
    "# инициализируем все, что необходимо для тренировки\n",
    "loss_model = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a9cc9c9-f42c-4823-8c28-e2e78484b809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], train_loss=7.4418, train_acc=0.4918, val_loss=0.6842, val_acc=0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], train_loss=0.6975, train_acc=0.4959, val_loss=0.6920, val_acc=0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], train_loss=0.6932, train_acc=0.5000, val_loss=0.6931, val_acc=0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], train_loss=0.6933, train_acc=0.5205, val_loss=0.6954, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], train_loss=0.6921, train_acc=0.5041, val_loss=0.6960, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], train_loss=0.6939, train_acc=0.5041, val_loss=0.6974, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], train_loss=0.6933, train_acc=0.5041, val_loss=0.6966, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], train_loss=0.6914, train_acc=0.5041, val_loss=0.6968, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], train_loss=0.6942, train_acc=0.5041, val_loss=0.6979, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], train_loss=0.6898, train_acc=0.5041, val_loss=0.6979, val_acc=0.4575\n",
      "Время обучения составило: 47.42 секунд.\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "EPOCHS = 10\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []\n",
    "best_loss = None\n",
    "count = 0\n",
    "\n",
    "start_time = time.time()  # Засекаем время начала тренировки модели\n",
    "# Цикл обучения\n",
    "for epoch in range(EPOCHS):\n",
    "    # Тренировка модели\n",
    "    model.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0\n",
    "    # добавим трейн луп, чтобы видеть прогресс обучения модели\n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        # Данные\n",
    "        # (batch.size, 1, 28, 28) --> (batch.size, 784)\n",
    "        # x = x.reshape(-1, 28*28).to(device)\n",
    "        x = x.to(device)\n",
    "        # (batch.size, int) --> (batch.size, 10), dtype=float32\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(2)[targets].to(device)\n",
    "\n",
    "        # Прямой проход + расчет ошибки модели\n",
    "        pred = model(x)\n",
    "        loss = loss_model(pred, targets)\n",
    "\n",
    "        # Обратный проход\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Шаг оптимизации\n",
    "        opt.step()\n",
    "\n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss)/len(running_train_loss)\n",
    "\n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "\n",
    "        train_loop.set_description(f\"Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Расчет значения метрики\n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "\n",
    "    # Сохранение значения функции потерь и метрики\n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "\n",
    "    # Проверка модели (Валидация)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        for x, targets in val_loader:\n",
    "            # Данные\n",
    "            # (batch.size, 1, 28, 28) --> (batch.size, 784)\n",
    "            # x = x.reshape(-1, 28*28).to(device)\n",
    "            x = x.to(device)\n",
    "            # (batch.size, int) --> (batch.size, 10), dtype=float32\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(2)[targets].to(device)\n",
    "\n",
    "            # Прямой проход + расчет ошибки модели\n",
    "            pred = model(x)\n",
    "            loss = loss_model(pred, targets)\n",
    "\n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss)/len(running_val_loss)\n",
    "\n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "\n",
    "        # Расчет значения метрики\n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "\n",
    "        # Сохранение значения функции потерь и метрики\n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "\n",
    "        lr_scheduler.step(mean_val_loss)\n",
    "        lr = lr_scheduler._last_lr[0]\n",
    "        lr_list.append(lr)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}, train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f}, val_acc={running_val_acc:.4f}\")\n",
    "\n",
    "        # # добавляем две проверки, для сохранения лучшей модели\n",
    "        # if best_loss is None:\n",
    "        #     best_loss = mean_val_loss\n",
    "      \n",
    "        # if mean_val_loss < best_loss:\n",
    "        #     best_loss = mean_val_loss\n",
    "            \n",
    "        #     # если модель улучшила свои показатели, то отсчет эпох пойдет заново\n",
    "        #     # обнуляем счетчик\n",
    "        #     count = 0\n",
    "            \n",
    "        #     # так же сохраняем словарь в случае улучшения модели\n",
    "        #     checkpoint = {\n",
    "        #         'state_model': model_with_Dropout.state_dict(),\n",
    "        #         'state_opt': opt.state_dict(),\n",
    "        #         'state_lr_scheduler': lr_scheduler.state_dict(),\n",
    "        #         'loss':{\n",
    "        #             'train_loss': train_loss,\n",
    "        #             'val_loss': val_loss,\n",
    "        #             'best_loss': best_loss\n",
    "        #         },\n",
    "        #         'metric':{\n",
    "        #             'train_acc': train_acc,\n",
    "        #             'val_acc': val_acc\n",
    "        #         },\n",
    "        #         'lr': lr_list,\n",
    "        #         'epoch':{\n",
    "        #             'EPOCHS': EPOCHS,\n",
    "        #             'save_epoch': epoch\n",
    "        #         }\n",
    "        #     }\n",
    "    \n",
    "            \n",
    "    \n",
    "        #     torch.save(checkpoint, f'model_state_dict_epoch_{epoch+1}.pt')\n",
    "        #     print(f\"На эпохе: {epoch+1}, сохранена модель со значением функции потерь на валидаци: {mean_val_loss:.4f}\", end='\\n\\n')\n",
    "\n",
    "        # # условие, для остановки обучения по достижению счетчиком определенного значения!\n",
    "        # if count >= 10:\n",
    "        #     print(f'\\033[31mОбучение остановлено на {epoch + 1} эпохе.\\033[0m')\n",
    "        #     break\n",
    "            \n",
    "        # # в конце каждой эпохи увеличиваем счетчик на 1\n",
    "        # count += 1\n",
    "\n",
    "# Засекаем время конца эпохи\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "print(f\"Время обучения составило: {train_time:.2f} секунд.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d471805d-247b-4865-b5b8-2f5fe0e22308",
   "metadata": {},
   "source": [
    "Довольно продолжительное количество времени для обучения. \n",
    "\n",
    "Автор не стал разбирать причин, поэтому мне предстоит сделать это самостоятельно.\n",
    "\n",
    "Опять же, результаты ответов модель на валидационной выборке осталвют желать лучшего)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b0ee8b-771a-483f-af28-4ceabfc58e71",
   "metadata": {},
   "source": [
    "#### Вариант 2\n",
    "1. Модель не обучена.\n",
    "2. Меняем весь классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c749151b-db95-4bfd-a0e8-136189c61ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Linear(in_features=25088, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализируем модельку\n",
    "model = models.vgg11()\n",
    "model.classifier = nn.Linear(512*7*7, 2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8dae8483-05e5-4b88-9109-7b6d4380dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переводим модель на cuda\n",
    "model = model.to(device)\n",
    "# инициализируем все, что необходимо для тренировки\n",
    "loss_model = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bc283f-39dc-435e-83a7-a9a05de64cfd",
   "metadata": {},
   "source": [
    "Ничего существенного от данной модели мы не ожидаем.\n",
    "\n",
    "Возомжно она будет обучаться чуть быстрее, из за меньшего кол-ва параметров, но не более того)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0696f42-80a5-407e-8917-14144c30bfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], train_loss=2.7804, train_acc=0.5861, val_loss=0.6775, val_acc=0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], train_loss=0.6964, train_acc=0.5082, val_loss=0.6762, val_acc=0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], train_loss=0.6892, train_acc=0.5697, val_loss=0.6762, val_acc=0.5686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], train_loss=0.6723, train_acc=0.6066, val_loss=0.6713, val_acc=0.5948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], train_loss=0.6568, train_acc=0.6516, val_loss=0.6760, val_acc=0.5294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], train_loss=0.6578, train_acc=0.6434, val_loss=0.7477, val_acc=0.4706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], train_loss=0.6788, train_acc=0.5738, val_loss=0.6346, val_acc=0.5752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], train_loss=0.6700, train_acc=0.5902, val_loss=0.8440, val_acc=0.6275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], train_loss=0.6966, train_acc=0.6025, val_loss=0.6880, val_acc=0.5294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], train_loss=0.6560, train_acc=0.6352, val_loss=0.6034, val_acc=0.6405\n",
      "Время обучения составило: 36.89 секунд.\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "EPOCHS = 10\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []\n",
    "best_loss = None\n",
    "count = 0\n",
    "\n",
    "start_time = time.time()  # Засекаем время начала тренировки модели\n",
    "# Цикл обучения\n",
    "for epoch in range(EPOCHS):\n",
    "    # Тренировка модели\n",
    "    model.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0\n",
    "    # добавим трейн луп, чтобы видеть прогресс обучения модели\n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        # Данные\n",
    "        # (batch.size, 1, 28, 28) --> (batch.size, 784)\n",
    "        # x = x.reshape(-1, 28*28).to(device)\n",
    "        x = x.to(device)\n",
    "        # (batch.size, int) --> (batch.size, 10), dtype=float32\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(2)[targets].to(device)\n",
    "\n",
    "        # Прямой проход + расчет ошибки модели\n",
    "        pred = model(x)\n",
    "        loss = loss_model(pred, targets)\n",
    "\n",
    "        # Обратный проход\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Шаг оптимизации\n",
    "        opt.step()\n",
    "\n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss)/len(running_train_loss)\n",
    "\n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "\n",
    "        train_loop.set_description(f\"Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Расчет значения метрики\n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "\n",
    "    # Сохранение значения функции потерь и метрики\n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "\n",
    "    # Проверка модели (Валидация)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        for x, targets in val_loader:\n",
    "            # Данные\n",
    "            # (batch.size, 1, 28, 28) --> (batch.size, 784)\n",
    "            # x = x.reshape(-1, 28*28).to(device)\n",
    "            x = x.to(device)\n",
    "            # (batch.size, int) --> (batch.size, 10), dtype=float32\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(2)[targets].to(device)\n",
    "\n",
    "            # Прямой проход + расчет ошибки модели\n",
    "            pred = model(x)\n",
    "            loss = loss_model(pred, targets)\n",
    "\n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss)/len(running_val_loss)\n",
    "\n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "\n",
    "        # Расчет значения метрики\n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "\n",
    "        # Сохранение значения функции потерь и метрики\n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "\n",
    "        lr_scheduler.step(mean_val_loss)\n",
    "        lr = lr_scheduler._last_lr[0]\n",
    "        lr_list.append(lr)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}, train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f}, val_acc={running_val_acc:.4f}\")\n",
    "\n",
    "# Засекаем время конца эпохи\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "print(f\"Время обучения составило: {train_time:.2f} секунд.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d5de70-4e81-4c18-a262-b5a843481f85",
   "metadata": {},
   "source": [
    "Как и ожидалось, модель обучилась за 37 секунд, против 47секунд в предыдущем обучении.\n",
    "\n",
    "Результаты модели на валидационной выборке стали даже немного лучше, конечно они не очень, но тем не менее)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f4b5a-e59b-4992-9394-bcd4df1c9143",
   "metadata": {},
   "source": [
    "### Обучение с применением TransferLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e5c10-0145-4d07-aa86-10397f0b62c1",
   "metadata": {},
   "source": [
    "#### Вариант 1.\n",
    "\n",
    "1. Модель обучена.\n",
    "2. Не замораживаем обученные параметры.\n",
    "3. Меняем только последний слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb453585-d7a0-4f41-b7d8-02de61ea0574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to /home/talium/.cache/torch/hub/checkpoints/vgg11-8a719046.pth\n",
      "\n",
      "00%|████████████████████████████████████████| 507M/507M [00:13<00:00, 40.5MB/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# берем предобученную модель и меням только последний слой классификатора\n",
    "model = models.vgg11(weights='DEFAULT')\n",
    "model.classifier[6] = nn.Linear(4096, 2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80e9e47a-fe92-45fb-94f0-f438f373cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переводим модель на cuda\n",
    "model = model.to(device)\n",
    "# инициализируем все, что необходимо для тренировки\n",
    "loss_model = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85d84452-1482-41dd-b93a-05569d8a765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], train_loss=1.1044, train_acc=0.5246, val_loss=0.7798, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], train_loss=0.7421, train_acc=0.5287, val_loss=0.8330, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], train_loss=0.7551, train_acc=0.4918, val_loss=0.7486, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], train_loss=0.7071, train_acc=0.4795, val_loss=0.7011, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], train_loss=0.7018, train_acc=0.5041, val_loss=0.6874, val_acc=0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], train_loss=0.6897, train_acc=0.5041, val_loss=0.7637, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], train_loss=0.7203, train_acc=0.5082, val_loss=0.6859, val_acc=0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], train_loss=0.7189, train_acc=0.4918, val_loss=0.6858, val_acc=0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], train_loss=0.7055, train_acc=0.5205, val_loss=0.6969, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], train_loss=0.7006, train_acc=0.5205, val_loss=0.6957, val_acc=0.4575\n",
      "Время обучения составило: 45.44 секунд.\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "EPOCHS = 10\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []\n",
    "best_loss = None\n",
    "count = 0\n",
    "\n",
    "start_time = time.time()  # Засекаем время начала тренировки модели\n",
    "# Цикл обучения\n",
    "for epoch in range(EPOCHS):\n",
    "    # Тренировка модели\n",
    "    model.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0\n",
    "    # добавим трейн луп, чтобы видеть прогресс обучения модели\n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        # Данные\n",
    "        # (batch.size, 1, 28, 28) --> (batch.size, 784)\n",
    "        # x = x.reshape(-1, 28*28).to(device)\n",
    "        x = x.to(device)\n",
    "        # (batch.size, int) --> (batch.size, 10), dtype=float32\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(2)[targets].to(device)\n",
    "\n",
    "        # Прямой проход + расчет ошибки модели\n",
    "        pred = model(x)\n",
    "        loss = loss_model(pred, targets)\n",
    "\n",
    "        # Обратный проход\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Шаг оптимизации\n",
    "        opt.step()\n",
    "\n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss)/len(running_train_loss)\n",
    "\n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "\n",
    "        train_loop.set_description(f\"Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Расчет значения метрики\n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "\n",
    "    # Сохранение значения функции потерь и метрики\n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "\n",
    "    # Проверка модели (Валидация)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        for x, targets in val_loader:\n",
    "            # Данные\n",
    "            # (batch.size, 1, 28, 28) --> (batch.size, 784)\n",
    "            # x = x.reshape(-1, 28*28).to(device)\n",
    "            x = x.to(device)\n",
    "            # (batch.size, int) --> (batch.size, 10), dtype=float32\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(2)[targets].to(device)\n",
    "\n",
    "            # Прямой проход + расчет ошибки модели\n",
    "            pred = model(x)\n",
    "            loss = loss_model(pred, targets)\n",
    "\n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss)/len(running_val_loss)\n",
    "\n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "\n",
    "        # Расчет значения метрики\n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "\n",
    "        # Сохранение значения функции потерь и метрики\n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "\n",
    "        lr_scheduler.step(mean_val_loss)\n",
    "        lr = lr_scheduler._last_lr[0]\n",
    "        lr_list.append(lr)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}, train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f}, val_acc={running_val_acc:.4f}\")\n",
    "\n",
    "# Засекаем время конца эпохи\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "print(f\"Время обучения составило: {train_time:.2f} секунд.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aee478-d783-4d98-8689-5006d2e1a01f",
   "metadata": {},
   "source": [
    "Модель с предобученными весами обучилась чуть быстрее нулевой, и даже показала результат местам лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f58d0a1-5695-480e-bdcb-9c53a3dca3cd",
   "metadata": {},
   "source": [
    "#### Вариант 2.\n",
    "\n",
    "1. Модель обучена.\n",
    "2. Не замораживаем обученные параметры.\n",
    "3. Меняем весь классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5df00209-5b30-4c9f-b6b8-aa58069a9dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Linear(in_features=25088, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# берем предобученную модель и меням весь классификатор\n",
    "model = models.vgg11(weights='DEFAULT')\n",
    "model.classifier = nn.Linear(512*7*7, 2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ab42507-ff60-4ea6-ba36-4be33b8ca1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переводим модель на cuda\n",
    "model = model.to(device)\n",
    "# инициализируем все, что необходимо для тренировки\n",
    "loss_model = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be674b80-3662-468d-b53b-6160d953e948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], train_loss=0.8331, train_acc=0.5000, val_loss=0.6835, val_acc=0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], train_loss=1.5598, train_acc=0.4590, val_loss=3.8223, val_acc=0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], train_loss=0.8555, train_acc=0.4918, val_loss=0.6934, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], train_loss=0.6932, train_acc=0.5041, val_loss=0.6936, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], train_loss=0.6930, train_acc=0.5041, val_loss=0.6937, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], train_loss=0.6939, train_acc=0.4959, val_loss=0.6939, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], train_loss=0.6932, train_acc=0.5041, val_loss=0.6941, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], train_loss=0.6933, train_acc=0.5041, val_loss=0.6941, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], train_loss=0.6933, train_acc=0.5041, val_loss=0.6940, val_acc=0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], train_loss=0.6933, train_acc=0.5041, val_loss=0.6940, val_acc=0.4575\n",
      "Время обучения составило: 36.91 секунд.\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "EPOCHS = 10\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []\n",
    "best_loss = None\n",
    "count = 0\n",
    "\n",
    "start_time = time.time()  # Засекаем время начала тренировки модели\n",
    "# Цикл обучения\n",
    "for epoch in range(EPOCHS):\n",
    "    # Тренировка модели\n",
    "    model.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0\n",
    "    # добавим трейн луп, чтобы видеть прогресс обучения модели\n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        # Данные\n",
    "        # (batch.size, 1, 28, 28) --> (batch.size, 784)\n",
    "        # x = x.reshape(-1, 28*28).to(device)\n",
    "        x = x.to(device)\n",
    "        # (batch.size, int) --> (batch.size, 10), dtype=float32\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(2)[targets].to(device)\n",
    "\n",
    "        # Прямой проход + расчет ошибки модели\n",
    "        pred = model(x)\n",
    "        loss = loss_model(pred, targets)\n",
    "\n",
    "        # Обратный проход\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Шаг оптимизации\n",
    "        opt.step()\n",
    "\n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss)/len(running_train_loss)\n",
    "\n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "\n",
    "        train_loop.set_description(f\"Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Расчет значения метрики\n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "\n",
    "    # Сохранение значения функции потерь и метрики\n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "\n",
    "    # Проверка модели (Валидация)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        for x, targets in val_loader:\n",
    "            # Данные\n",
    "            # (batch.size, 1, 28, 28) --> (batch.size, 784)\n",
    "            # x = x.reshape(-1, 28*28).to(device)\n",
    "            x = x.to(device)\n",
    "            # (batch.size, int) --> (batch.size, 10), dtype=float32\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(2)[targets].to(device)\n",
    "\n",
    "            # Прямой проход + расчет ошибки модели\n",
    "            pred = model(x)\n",
    "            loss = loss_model(pred, targets)\n",
    "\n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss)/len(running_val_loss)\n",
    "\n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "\n",
    "        # Расчет значения метрики\n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "\n",
    "        # Сохранение значения функции потерь и метрики\n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "\n",
    "        lr_scheduler.step(mean_val_loss)\n",
    "        lr = lr_scheduler._last_lr[0]\n",
    "        lr_list.append(lr)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}, train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f}, val_acc={running_val_acc:.4f}\")\n",
    "\n",
    "# Засекаем время конца эпохи\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "print(f\"Время обучения составило: {train_time:.2f} секунд.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491bb5b-5ca5-4d38-8c05-4a9eb797461b",
   "metadata": {},
   "source": [
    "Такой способ показал существенно более лучший результат по времени обучения модели.\n",
    "Но, к сожалению, метрика качества на валидации выглядит печально)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c27712-01c6-4565-a932-91f5a0b2a278",
   "metadata": {},
   "source": [
    "#### Вариант 3.\n",
    "\n",
    "1. Модель обучена.\n",
    "2. Замораживаем обученные параметры.\n",
    "3. Меняем весь классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40261177-6050-4ef0-b024-c33006e4444a",
   "metadata": {},
   "source": [
    "Мы замораживаем вычисление градиентов. Если градиенты не вычисляются, то и оптимизатору нечего обновлять)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1dd79d6-c536-45b0-a00e-d99fd4de3655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Linear(in_features=25088, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# берем предобученную модель и меням весь классификатор\n",
    "model = models.vgg11(weights='DEFAULT')\n",
    "\n",
    "# циклично замораживаем все слои\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.classifier = nn.Linear(512*7*7, 2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b6cf2157-c13f-4042-8e73-037af3d77d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.3\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.6\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.8\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.11\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.13\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.16\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.18\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "classifier\n",
      " weights.requires_grad = True\n",
      " bais.requires_grad = True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# наглядно убедимся в заморозке слоев\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "        print(name)\n",
    "        for i, param in enumerate(layer.parameters()):\n",
    "            if i == 0:\n",
    "                print(f' weights.requires_grad = {param.requires_grad}')\n",
    "            else:\n",
    "                print(f' bais.requires_grad = {param.requires_grad}', end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2956a993-3be4-4d1c-8803-0a1aad1b7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переводим модель на cuda\n",
    "model = model.to(device)\n",
    "# инициализируем все, что необходимо для тренировки\n",
    "loss_model = nn.CrossEntropyLoss()\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6604c99c-94bc-49e9-8176-42e6fe1e6593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# произведем изменения в оптимизаторе\n",
    "# в него мы будем передавать только те параметры. которые хотим обновлять\n",
    "# то есть параметры классификатора\n",
    "opt = torch.optim.Adam(model.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "606b1ce0-8cae-4ec0-9941-7cc3a21a0ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], train_loss=0.6503, train_acc=0.7869, val_loss=0.4979, val_acc=0.9346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], train_loss=0.2766, train_acc=0.9262, val_loss=0.6914, val_acc=0.9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], train_loss=0.1938, train_acc=0.9426, val_loss=0.6072, val_acc=0.9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], train_loss=0.1353, train_acc=0.9590, val_loss=0.5701, val_acc=0.9150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], train_loss=0.0843, train_acc=0.9713, val_loss=0.5835, val_acc=0.9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], train_loss=0.0944, train_acc=0.9754, val_loss=0.7952, val_acc=0.9281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], train_loss=0.0204, train_acc=0.9918, val_loss=0.7732, val_acc=0.9150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], train_loss=0.0835, train_acc=0.9836, val_loss=0.7177, val_acc=0.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], train_loss=0.1490, train_acc=0.9590, val_loss=0.9142, val_acc=0.9020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], train_loss=0.0597, train_acc=0.9754, val_loss=0.8306, val_acc=0.9150\n",
      "Время обучения составило: 25.10 секунд.\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "EPOCHS = 10\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []\n",
    "best_loss = None\n",
    "count = 0\n",
    "\n",
    "start_time = time.time()  # Засекаем время начала тренировки модели\n",
    "# Цикл обучения\n",
    "for epoch in range(EPOCHS):\n",
    "    # Тренировка модели\n",
    "    model.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0\n",
    "    # добавим трейн луп, чтобы видеть прогресс обучения модели\n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        # Данные\n",
    "        # (batch.size, 1, 28, 28) --> (batch.size, 784)\n",
    "        # x = x.reshape(-1, 28*28).to(device)\n",
    "        x = x.to(device)\n",
    "        # (batch.size, int) --> (batch.size, 10), dtype=float32\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(2)[targets].to(device)\n",
    "\n",
    "        # Прямой проход + расчет ошибки модели\n",
    "        pred = model(x)\n",
    "        loss = loss_model(pred, targets)\n",
    "\n",
    "        # Обратный проход\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Шаг оптимизации\n",
    "        opt.step()\n",
    "\n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss)/len(running_train_loss)\n",
    "\n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "\n",
    "        train_loop.set_description(f\"Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Расчет значения метрики\n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "\n",
    "    # Сохранение значения функции потерь и метрики\n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "\n",
    "    # Проверка модели (Валидация)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        for x, targets in val_loader:\n",
    "            # Данные\n",
    "            # (batch.size, 1, 28, 28) --> (batch.size, 784)\n",
    "            # x = x.reshape(-1, 28*28).to(device)\n",
    "            x = x.to(device)\n",
    "            # (batch.size, int) --> (batch.size, 10), dtype=float32\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(2)[targets].to(device)\n",
    "\n",
    "            # Прямой проход + расчет ошибки модели\n",
    "            pred = model(x)\n",
    "            loss = loss_model(pred, targets)\n",
    "\n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss)/len(running_val_loss)\n",
    "\n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "\n",
    "        # Расчет значения метрики\n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "\n",
    "        # Сохранение значения функции потерь и метрики\n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "\n",
    "        lr_scheduler.step(mean_val_loss)\n",
    "        lr = lr_scheduler._last_lr[0]\n",
    "        lr_list.append(lr)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}, train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f}, val_acc={running_val_acc:.4f}\")\n",
    "\n",
    "# Засекаем время конца эпохи\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "print(f\"Время обучения составило: {train_time:.2f} секунд.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97075a0a-10b8-4e61-88e1-1b3330f06282",
   "metadata": {},
   "source": [
    "Обучение полетело. как ракета прям =)))\n",
    "Точность на валидации существенно лучше!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c17ccc-4a84-4c5b-b95e-87eb3b002b61",
   "metadata": {},
   "source": [
    "#### Вариант 4.\n",
    "Finetuning.\n",
    "\n",
    "Часть сверточных слоев размораживается, но при этом скорость обучения существенно ниже, чтобы не сильно вносить изменения в данные слои."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2635759-743d-496a-8ccb-9ab52a954124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# берем предобученную модель и меням весь классификатор\n",
    "model = models.vgg11(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7b9f74d3-4730-4df3-8baf-368496e8c9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (14): ReLU(inplace=True)\n",
       "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (17): ReLU(inplace=True)\n",
       "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (19): ReLU(inplace=True)\n",
       "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Демонстрация будет произведена на данных слоях\n",
    "model.features[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a543b0a-b498-486f-9d8f-3aba1d10de1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Linear(in_features=25088, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# циклично замораживаем все слои\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "    \n",
    "model.classifier = nn.Linear(512*7*7, 2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "de597c4b-69a9-4621-b39a-ef9c3aca7623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.3\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.6\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.8\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.11\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.13\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.16\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.18\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "classifier\n",
      " weights.requires_grad = True\n",
      " bais.requires_grad = True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# наглядно убедимся в заморозке слоев\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "        print(name)\n",
    "        for i, param in enumerate(layer.parameters()):\n",
    "            if i == 0:\n",
    "                print(f' weights.requires_grad = {param.requires_grad}')\n",
    "            else:\n",
    "                print(f' bais.requires_grad = {param.requires_grad}', end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af09241a-89ad-4ebe-a981-bc54149777a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разморозим те, на которых будем дообучать\n",
    "for param in model.features[13:].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62f647b0-a410-44ab-9884-859aeb4c3c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.3\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.6\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.8\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.11\n",
      " weights.requires_grad = False\n",
      " bais.requires_grad = False\n",
      "\n",
      "features.13\n",
      " weights.requires_grad = True\n",
      " bais.requires_grad = True\n",
      "\n",
      "features.16\n",
      " weights.requires_grad = True\n",
      " bais.requires_grad = True\n",
      "\n",
      "features.18\n",
      " weights.requires_grad = True\n",
      " bais.requires_grad = True\n",
      "\n",
      "classifier\n",
      " weights.requires_grad = True\n",
      " bais.requires_grad = True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# наглядно убедимся в разморозке слоев\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "        print(name)\n",
    "        for i, param in enumerate(layer.parameters()):\n",
    "            if i == 0:\n",
    "                print(f' weights.requires_grad = {param.requires_grad}')\n",
    "            else:\n",
    "                print(f' bais.requires_grad = {param.requires_grad}', end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "11b3ef7e-6a22-4816-b247-9a26a21ad326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переводим модель на cuda\n",
    "model = model.to(device)\n",
    "# инициализируем все, что необходимо для тренировки\n",
    "loss_model = nn.CrossEntropyLoss()\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4f25de9c-aa10-4cf5-b032-d9dda96e2f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# снова произведем изменения в оптимизаторе\n",
    "# для размороженных слоев lr снизим\n",
    "# таким образом можно устанавлиавать для разные параметров разную скорость обучения\n",
    "opt = torch.optim.Adam(\n",
    "    [\n",
    "        {'params':model.features[13:].parameters(), 'lr':0.000001},\n",
    "        {'params':model.classifier.parameters()}\n",
    "    ],\n",
    "    lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "11671dfa-c13d-4e69-bff4-cd3cf417f13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], train_loss=0.5396, train_acc=0.7254, val_loss=0.3293, val_acc=0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], train_loss=0.2705, train_acc=0.9098, val_loss=0.2459, val_acc=0.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], train_loss=0.1644, train_acc=0.9467, val_loss=0.2245, val_acc=0.9281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], train_loss=0.1156, train_acc=0.9795, val_loss=0.2237, val_acc=0.9281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], train_loss=0.0986, train_acc=0.9836, val_loss=0.2246, val_acc=0.9346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], train_loss=0.0916, train_acc=0.9754, val_loss=0.2231, val_acc=0.9346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], train_loss=0.0700, train_acc=0.9836, val_loss=0.2370, val_acc=0.9281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], train_loss=0.0586, train_acc=0.9877, val_loss=0.2335, val_acc=0.9412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], train_loss=0.0840, train_acc=0.9877, val_loss=0.2551, val_acc=0.9281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], train_loss=0.0390, train_acc=1.0000, val_loss=0.2290, val_acc=0.9412\n",
      "Время обучения составило: 28.45 секунд.\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "EPOCHS = 10\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []\n",
    "best_loss = None\n",
    "count = 0\n",
    "\n",
    "start_time = time.time()  # Засекаем время начала тренировки модели\n",
    "# Цикл обучения\n",
    "for epoch in range(EPOCHS):\n",
    "    # Тренировка модели\n",
    "    model.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0\n",
    "    # добавим трейн луп, чтобы видеть прогресс обучения модели\n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        # Данные\n",
    "        # (batch.size, 1, 28, 28) --> (batch.size, 784)\n",
    "        # x = x.reshape(-1, 28*28).to(device)\n",
    "        x = x.to(device)\n",
    "        # (batch.size, int) --> (batch.size, 10), dtype=float32\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(2)[targets].to(device)\n",
    "\n",
    "        # Прямой проход + расчет ошибки модели\n",
    "        pred = model(x)\n",
    "        loss = loss_model(pred, targets)\n",
    "\n",
    "        # Обратный проход\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Шаг оптимизации\n",
    "        opt.step()\n",
    "\n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss)/len(running_train_loss)\n",
    "\n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "\n",
    "        train_loop.set_description(f\"Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Расчет значения метрики\n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "\n",
    "    # Сохранение значения функции потерь и метрики\n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "\n",
    "    # Проверка модели (Валидация)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        for x, targets in val_loader:\n",
    "            # Данные\n",
    "            # (batch.size, 1, 28, 28) --> (batch.size, 784)\n",
    "            # x = x.reshape(-1, 28*28).to(device)\n",
    "            x = x.to(device)\n",
    "            # (batch.size, int) --> (batch.size, 10), dtype=float32\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(2)[targets].to(device)\n",
    "\n",
    "            # Прямой проход + расчет ошибки модели\n",
    "            pred = model(x)\n",
    "            loss = loss_model(pred, targets)\n",
    "\n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss)/len(running_val_loss)\n",
    "\n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "\n",
    "        # Расчет значения метрики\n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "\n",
    "        # Сохранение значения функции потерь и метрики\n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "\n",
    "        lr_scheduler.step(mean_val_loss)\n",
    "        lr = lr_scheduler._last_lr[0]\n",
    "        lr_list.append(lr)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}, train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f}, val_acc={running_val_acc:.4f}\")\n",
    "\n",
    "# Засекаем время конца эпохи\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "print(f\"Время обучения составило: {train_time:.2f} секунд.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c536a61-d7cc-47c8-a4f9-02fab75eb5a6",
   "metadata": {},
   "source": [
    "Точность модели на валидации не сказать, что выросла, но небольшую \"Подвижку\" можно наблюдать по отношению к прошлому обучению.\n",
    "\n",
    "Так же стоит отметить, что функция потерь на валидации существенно снизилась. Это гуд =)\n",
    "\n",
    "В общем то теперь необходимо заниматься практикой!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
